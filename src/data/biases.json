[
  {
    "id": 1,
    "name": "Confirmation Bias",
    "nameFr": "Biais de confirmation",
    "slug": "confirmation-bias",
    "summary": "Seeking information that confirms your existing beliefs",
    "summaryFr": "Rechercher des informations qui confirment vos croyances existantes",
    "description": "Confirmation bias is one of the most pervasive cognitive biases, affecting virtually every domain of human decision-making. It operates through multiple mechanisms: selective attention (noticing information that supports our beliefs), biased interpretation (interpreting ambiguous information as supportive), biased memory (better recall of confirming information), and biased search (actively seeking supporting evidence while avoiding contradictory data). This bias is particularly dangerous because it creates self-reinforcing belief systems that become increasingly resistant to correction. Research by psychologist Peter Wason demonstrated this through his famous \"2-4-6 task\" where participants consistently tried to confirm rather than falsify their hypotheses. In professional settings, confirmation bias can lead to poor hiring decisions, failed projects, and strategic errors. In personal life, it can damage relationships and prevent personal growth. The bias is amplified by emotional investment in a belief and by the echo chambers created by social media algorithms.",
    "descriptionFr": "Le biais de confirmation est l\\'un des biais cognitifs les plus répandus, affectant virtuellement tous les domaines de la prise de décision humaine. Il opère à travers plusieurs mécanismes : l\\'attention sélective (remarquer les informations qui soutiennent nos croyances), l\\'interprétation biaisée (interpréter les informations ambiguës comme favorables), la mémoire biaisée (meilleur rappel des informations confirmantes), et la recherche biaisée (chercher activement des preuves favorables tout en évitant les données contradictoires). Ce biais est particulièrement dangereux car il crée des systèmes de croyances auto-renforçants qui deviennent de plus en plus résistants à la correction. Le psychologue Peter Wason l\\'a démontré avec sa célèbre \"tâche 2-4-6\" où les participants essayaient systématiquement de confirmer plutôt que de réfuter leurs hypothèses. En contexte professionnel, le biais de confirmation peut mener à de mauvaises décisions d\\'embauche, des projets échoués et des erreurs stratégiques. Dans la vie personnelle, il peut endommager les relations et empêcher la croissance personnelle. Ce biais est amplifié par l\\'investissement émotionnel dans une croyance et par les chambres d\\'écho créées par les algorithmes des réseaux sociaux.",
    "example": "When hiring, focusing on a candidate\\'s strengths that match your initial impression while overlooking red flags. Or when investing, only reading positive news about stocks you own while dismissing warnings.",
    "exampleFr": "Lors d\\'un recrutement, se concentrer sur les forces d\\'un candidat qui correspondent à votre première impression tout en ignorant les signaux d\\'alarme. Ou en investissant, ne lire que les nouvelles positives sur les actions que vous possédez tout en rejetant les avertissements.",
    "icon": "target"
  },
  {
    "id": 2,
    "name": "Anchoring Bias",
    "nameFr": "Biais d\\'ancrage",
    "slug": "anchoring-bias",
    "summary": "Over-relying on the first piece of information received",
    "summaryFr": "Se fier excessivement à la première information reçue",
    "description": "Anchoring bias, first documented by psychologists Amos Tversky and Daniel Kahneman, is a cognitive shortcut where the brain uses an initial piece of information as a reference point for all subsequent judgments. This anchor can be entirely arbitrary and still powerfully influence decisions. In famous experiments, even spinning a random wheel of fortune affected participants\\' estimates of unrelated quantities. The bias operates unconsciously—knowing about it doesn\\'t make you immune. Professional negotiators, salespeople, and marketers regularly exploit anchoring by strategically choosing initial offers or price displays. In negotiations, whoever makes the first offer often \"anchors\" the entire discussion. The bias affects everything from salary negotiations to medical diagnoses to sentencing recommendations. Even experts in their fields fall prey to anchoring. The adjustment from an anchor is typically insufficient, meaning final estimates remain biased toward the initial value regardless of how irrational it may be.",
    "descriptionFr": "Le biais d\\'ancrage, documenté pour la première fois par les psychologues Amos Tversky et Daniel Kahneman, est un raccourci cognitif où le cerveau utilise une première information comme point de référence pour tous les jugements suivants. Cette ancre peut être entièrement arbitraire et néanmoins influencer puissamment les décisions. Dans des expériences célèbres, même tourner une roue de fortune aléatoire affectait les estimations des participants sur des quantités sans rapport. Le biais opère inconsciemment—le connaître ne vous immunise pas. Les négociateurs professionnels, vendeurs et marketeurs exploitent régulièrement l\\'ancrage en choisissant stratégiquement les offres initiales ou les affichages de prix. Dans les négociations, celui qui fait la première offre \"ancre\" souvent toute la discussion. Le biais affecte tout, des négociations salariales aux diagnostics médicaux aux recommandations de condamnation. Même les experts dans leurs domaines succombent à l\\'ancrage. L\\'ajustement depuis une ancre est typiquement insuffisant, ce qui signifie que les estimations finales restent biaisées vers la valeur initiale, peu importe à quel point elle peut être irrationnelle.",
    "example": "If a house is listed at $500,000, you might think $450,000 is a great deal, even if it\\'s only worth $400,000. Or in salary negotiations, the first number mentioned often determines the final outcome.",
    "exampleFr": "Si une maison est affichée à 500 000 $, vous pourriez penser que 450 000 $ est une bonne affaire, même si elle ne vaut que 400 000 $. Ou dans les négociations salariales, le premier chiffre mentionné détermine souvent le résultat final.",
    "icon": "eye"
  },
  {
    "id": 3,
    "name": "Sunk Cost Fallacy",
    "nameFr": "Sophisme des coûts irrécupérables",
    "slug": "sunk-cost-fallacy",
    "summary": "Continuing something because of past investments",
    "summaryFr": "Continuer quelque chose à cause des investissements passés",
    "description": "The sunk cost fallacy is a deeply ingrained cognitive error where we continue a behavior or endeavor because of previously invested resources (time, money, effort) rather than evaluating future value objectively. Economically rational decision-making requires ignoring sunk costs since they cannot be recovered regardless of future choices. However, humans struggle with this concept due to loss aversion and a need to justify past decisions. The fallacy is amplified when investments are visible to others, making it harder to admit \"failure\" by stopping. Classic examples include the Concorde jet project (the \"Concorde fallacy\"), where governments continued investing billions despite clear evidence of commercial non-viability. In personal life, it manifests as staying in unfulfilling relationships, finishing bad books, or eating food you don\\'t want just because you paid for it. Organizations often escalate commitment to failing projects, throwing good money after bad. Breaking free requires reframing the decision: ask not \"how can I justify what I\\'ve spent?\" but \"if I were starting fresh today, would I choose this path?\"",
    "descriptionFr": "Le sophisme des coûts irrécupérables est une erreur cognitive profondément ancrée où nous continuons un comportement ou une entreprise en raison des ressources précédemment investies (temps, argent, effort) plutôt que d\\'évaluer objectivement la valeur future. La prise de décision économiquement rationnelle exige d\\'ignorer les coûts irrécupérables puisqu\\'ils ne peuvent être récupérés quel que soit le choix futur. Cependant, les humains peinent avec ce concept en raison de l\\'aversion à la perte et du besoin de justifier les décisions passées. Le sophisme est amplifié lorsque les investissements sont visibles par d\\'autres, rendant plus difficile d\\'admettre \"l\\'échec\" en s\\'arrêtant. Les exemples classiques incluent le projet Concorde (le \"sophisme du Concorde\"), où les gouvernements ont continué à investir des milliards malgré des preuves claires de non-viabilité commerciale. Dans la vie personnelle, cela se manifeste en restant dans des relations insatisfaisantes, finir de mauvais livres, ou manger de la nourriture qu\\'on ne veut pas juste parce qu\\'on l\\'a payée. Les organisations escaladent souvent leur engagement dans des projets en échec. Se libérer nécessite de recadrer la décision : ne demandez pas \"comment puis-je justifier ce que j\\'ai dépensé?\" mais \"si je recommençais aujourd\\'hui, choisirais-je cette voie?\"",
    "example": "Staying in a failing project because you\\'ve already spent months on it. Watching a terrible movie to the end because you paid for the ticket. Keeping clothes you never wear because they were expensive.",
    "exampleFr": "Rester dans un projet qui échoue parce que vous y avez déjà passé des mois. Regarder un film terrible jusqu\\'à la fin parce que vous avez payé le billet. Garder des vêtements que vous ne portez jamais parce qu\\'ils étaient chers.",
    "icon": "scale"
  },
  {
    "id": 4,
    "name": "Halo Effect",
    "nameFr": "Effet de halo",
    "slug": "halo-effect",
    "summary": "Letting one positive trait influence overall judgment",
    "summaryFr": "Laisser un trait positif influencer le jugement global",
    "description": "The halo effect, first identified by psychologist Edward Thorndike in 1920, is a cognitive bias where our impression of someone in one area influences our opinion of them in other unrelated areas. If we perceive someone positively in one domain (attractive, intelligent, friendly), we tend to assume they possess other positive qualities as well. This creates a \"halo\" of positive attributes around them. The effect works in reverse too—the \"horn effect\" causes us to assume negative traits based on one negative impression. Research shows physically attractive people are assumed to be more intelligent, successful, and trustworthy, despite no actual correlation. In hiring, candidates from prestigious universities or famous companies receive more favorable evaluations across all dimensions. The halo effect distorts performance reviews, where one strong characteristic overshadows weaknesses. Marketing exploits this by using attractive spokespeople. Even judges and juries are affected—studies show attractive defendants receive lighter sentences. Breaking the halo effect requires deliberately evaluating each attribute independently and seeking contradicting evidence to our global impressions.",
    "descriptionFr": "L\\'effet de halo, identifié pour la première fois par le psychologue Edward Thorndike en 1920, est un biais cognitif où notre impression de quelqu\\'un dans un domaine influence notre opinion sur lui dans d\\'autres domaines sans rapport. Si nous percevons quelqu\\'un positivement dans un domaine (attrayant, intelligent, amical), nous tendons à supposer qu\\'il possède aussi d\\'autres qualités positives. Cela crée un \"halo\" d\\'attributs positifs autour de lui. L\\'effet fonctionne aussi à l\\'inverse—l\\'\"effet de corne\" nous fait supposer des traits négatifs basés sur une impression négative. La recherche montre que les personnes physiquement attrayantes sont supposées plus intelligentes, réussies et dignes de confiance, malgré l\\'absence de corrélation réelle. En recrutement, les candidats d\\'universités prestigieuses ou d\\'entreprises célèbres reçoivent des évaluations plus favorables sur toutes les dimensions. L\\'effet de halo déforme les évaluations de performance, où une caractéristique forte éclipse les faiblesses. Le marketing exploite cela avec des porte-paroles attrayants. Même les juges et jurés sont affectés—les études montrent que les accusés attrayants reçoivent des peines plus légères. Briser l\\'effet de halo nécessite d\\'évaluer délibérément chaque attribut indépendamment.",
    "example": "A candidate from a prestigious university being assumed competent in all areas. An attractive person assumed to be more honest. A successful entrepreneur assumed to be a good manager.",
    "exampleFr": "Un candidat d\\'une université prestigieuse supposé compétent dans tous les domaines. Une personne attrayante supposée plus honnête. Un entrepreneur à succès supposé être un bon manager.",
    "icon": "clock"
  },
  {
    "id": 5,
    "name": "Availability Bias",
    "nameFr": "Biais de disponibilité",
    "slug": "availability-bias",
    "summary": "Overweighting easily recalled information",
    "summaryFr": "Surpondérer les informations facilement mémorisées",
    "description": "The availability heuristic, identified by Kahneman and Tversky, is the tendency to judge the frequency or probability of an event by how easily examples come to mind. Events that are recent, dramatic, or emotionally charged are more \"available\" to memory and thus seem more common than they actually are. This explains why people overestimate risks of plane crashes (dramatic news coverage) while underestimating risks of car accidents (mundane and unreported). Media coverage heavily distorts our risk perception—we fear terrorism more than heart disease despite vast differences in actual risk. In business, recent failures loom large in memory while past successes fade, leading to excessive risk aversion. Conversely, a recent success can breed overconfidence. The bias affects medical diagnoses (doctors over-diagnose conditions they\\'ve recently seen), investment decisions (recent market events dominate thinking), and policy-making (responses driven by recent crises). To counteract availability bias, seek statistical data rather than relying on memorable examples, and deliberately consider base rates and historical patterns rather than recent events alone.",
    "descriptionFr": "L\\'heuristique de disponibilité, identifiée par Kahneman et Tversky, est la tendance à juger la fréquence ou la probabilité d\\'un événement par la facilité avec laquelle les exemples viennent à l\\'esprit. Les événements récents, dramatiques ou chargés émotionnellement sont plus \"disponibles\" en mémoire et semblent donc plus courants qu\\'ils ne le sont réellement. Cela explique pourquoi les gens surestiment les risques d\\'accidents d\\'avion (couverture médiatique dramatique) tout en sous-estimant les risques d\\'accidents de voiture (banals et non rapportés). La couverture médiatique déforme fortement notre perception du risque—nous craignons plus le terrorisme que les maladies cardiaques malgré d\\'énormes différences de risque réel. En affaires, les échecs récents pèsent lourd dans la mémoire tandis que les succès passés s\\'estompent, menant à une aversion au risque excessive. Inversement, un succès récent peut engendrer un excès de confiance. Le biais affecte les diagnostics médicaux (les médecins surdiagnostiquent les conditions récemment vues), les décisions d\\'investissement (les événements récents du marché dominent la pensée), et la politique. Pour contrer le biais de disponibilité, cherchez des données statistiques plutôt que de vous fier aux exemples mémorables.",
    "example": "After a project failure, overestimating the risk of new projects. Fearing plane crashes more than car accidents. Overweighting negative feedback from a recent meeting.",
    "exampleFr": "Après un échec de projet, surestimer le risque de nouveaux projets. Craindre les accidents d\\'avion plus que les accidents de voiture. Surpondérer les retours négatifs d\\'une réunion récente.",
    "icon": "zap"
  },
  {
    "id": 6,
    "name": "Overconfidence Bias",
    "nameFr": "Biais de surconfiance",
    "slug": "overconfidence-bias",
    "summary": "Being more confident than accuracy warrants",
    "summaryFr": "Être plus confiant que votre exactitude ne le justifie",
    "description": "Overconfidence bias is one of the most robust and damaging cognitive biases, manifesting in three forms: overestimation (thinking we perform better than we do), overplacement (thinking we\\'re better than others), and overprecision (excessive certainty in our beliefs). Research consistently shows that people rate themselves above average on most positive traits—a statistical impossibility. Professionals are especially prone: studies show that doctors, lawyers, and executives consistently overestimate their accuracy. Entrepreneurs display particularly high overconfidence, which may explain both why they start businesses and why so many fail. In forecasting, experts regularly assign 90% confidence to predictions that prove wrong 40% of the time. The bias is resistant to feedback because we rationalize failures as bad luck while attributing successes to skill. Overconfidence leads to inadequate preparation, poor risk assessment, insufficient contingency planning, and the illusion that complex problems have simple solutions. Paradoxically, the most competent people are often the least overconfident (the Dunning-Kruger effect in reverse). Calibrating confidence requires tracking predictions over time and deliberately considering scenarios where you could be wrong.",
    "descriptionFr": "Le biais de surconfiance est l\\'un des biais cognitifs les plus robustes et dommageables, se manifestant sous trois formes : la surestimation (penser que nous performons mieux que nous le faisons), le surplacement (penser que nous sommes meilleurs que les autres), et la surprécision (certitude excessive dans nos croyances). La recherche montre constamment que les gens s\\'évaluent au-dessus de la moyenne sur la plupart des traits positifs—une impossibilité statistique. Les professionnels sont particulièrement concernés : les études montrent que les médecins, avocats et dirigeants surestiment constamment leur précision. Les entrepreneurs affichent une surconfiance particulièrement élevée, ce qui peut expliquer pourquoi ils créent des entreprises et pourquoi tant échouent. En prévision, les experts assignent régulièrement 90% de confiance à des prédictions qui s\\'avèrent fausses 40% du temps. Le biais résiste au feedback car nous rationalisons les échecs comme de la malchance tout en attribuant les succès à nos compétences. La surconfiance mène à une préparation inadéquate, une mauvaise évaluation des risques, une planification d\\'urgence insuffisante. Calibrer sa confiance nécessite de suivre ses prédictions dans le temps et de considérer délibérément les scénarios où l\\'on pourrait avoir tort.",
    "example": "Believing a project will take 3 months when similar projects took 6+ months. Rating yourself as an above-average driver. Being 99% sure of an answer that turns out wrong.",
    "exampleFr": "Croire qu\\'un projet prendra 3 mois quand des projets similaires ont pris plus de 6 mois. S\\'évaluer comme un conducteur au-dessus de la moyenne. Être sûr à 99% d\\'une réponse qui s\\'avère fausse.",
    "icon": "shield"
  },
  {
    "id": 7,
    "name": "Status Quo Bias",
    "nameFr": "Biais du statu quo",
    "slug": "status-quo-bias",
    "summary": "Preference for the current state of affairs",
    "summaryFr": "Préférence pour l\\'état actuel des choses",
    "description": "Status quo bias is the tendency to prefer the current state of affairs over change, even when change would be objectively beneficial. This bias stems from multiple psychological mechanisms: loss aversion (potential losses from change loom larger than potential gains), mere exposure effect (familiarity breeds preference), regret avoidance (we fear regretting active choices more than passive ones), and cognitive ease (the current situation requires no mental effort to understand). Research on retirement savings shows people rarely change default options, even when doing so would substantially increase their wealth. In organizations, status quo bias manifests as resistance to process improvements, reluctance to adopt new technologies, and preference for \"the way we\\'ve always done it.\" The bias is exploited through \"opt-out\" rather than \"opt-in\" defaults. Switching costs—real or perceived—amplify status quo bias, as do previous investments in the current situation. Breaking free requires consciously evaluating the current state as just one option among many, asking \"if I weren\\'t already in this situation, would I choose it?\", and calculating the true costs of inaction versus action.",
    "descriptionFr": "Le biais du statu quo est la tendance à préférer l\\'état actuel des choses au changement, même quand le changement serait objectivement bénéfique. Ce biais découle de multiples mécanismes psychologiques : l\\'aversion à la perte (les pertes potentielles du changement semblent plus grandes que les gains potentiels), l\\'effet de simple exposition (la familiarité engendre la préférence), l\\'évitement du regret (nous craignons plus de regretter les choix actifs que passifs), et la facilité cognitive (la situation actuelle ne demande aucun effort mental à comprendre). La recherche sur l\\'épargne-retraite montre que les gens changent rarement les options par défaut, même si cela augmenterait substantiellement leur richesse. Dans les organisations, le biais du statu quo se manifeste par la résistance aux améliorations de processus, la réticence à adopter de nouvelles technologies, et la préférence pour \"la façon dont on a toujours fait.\" Le biais est exploité via les options \"opt-out\" plutôt que \"opt-in.\" Les coûts de changement—réels ou perçus—amplifient le biais. S\\'en libérer nécessite d\\'évaluer consciemment l\\'état actuel comme une option parmi d\\'autres, en demandant \"si je n\\'étais pas déjà dans cette situation, la choisirais-je?\"",
    "example": "Staying in a job you dislike because change feels risky. Keeping the same phone provider despite better deals. Using outdated software because \"it works.\"",
    "exampleFr": "Rester dans un emploi que vous n\\'aimez pas parce que le changement semble risqué. Garder le même opérateur téléphonique malgré de meilleures offres. Utiliser un logiciel obsolète parce qu\\'\"il fonctionne.\"",
    "icon": "users"
  },
  {
    "id": 8,
    "name": "Affinity Bias",
    "nameFr": "Biais d\\'affinité",
    "slug": "affinity-bias",
    "summary": "Favoring people similar to yourself",
    "summaryFr": "Favoriser les personnes qui vous ressemblent",
    "description": "Affinity bias, also called similarity bias or \"like me\" bias, is the unconscious tendency to prefer people who share similar qualities, backgrounds, interests, or experiences with ourselves. Evolutionary psychology suggests this developed as a survival mechanism—trusting those similar to us was often adaptive. However, in modern contexts, it leads to discrimination, homogeneous teams, and poor decision-making. The bias operates on multiple dimensions: demographics (age, gender, ethnicity), education (same schools, degrees), interests (hobbies, sports), communication style, and personality. In hiring, it manifests as preferring candidates who \"fit the culture\" or with whom interviewers feel a natural rapport. Research shows interviewers often decide within seconds based on superficial similarities. Affinity bias reinforces existing power structures and reduces diversity. It creates echo chambers where similar people confirm each other\\'s views. The bias is particularly insidious because we experience it as genuine connection rather than prejudice. Counteracting it requires structured evaluation criteria, diverse interview panels, blind resume reviews, and actively seeking out people who challenge your perspectives rather than confirm them.",
    "descriptionFr": "Le biais d\\'affinité, aussi appelé biais de similarité ou biais \"comme moi,\" est la tendance inconsciente à préférer les personnes qui partagent des qualités, parcours, intérêts ou expériences similaires aux nôtres. La psychologie évolutionnaire suggère que cela s\\'est développé comme mécanisme de survie—faire confiance à ceux qui nous ressemblent était souvent adaptatif. Cependant, dans les contextes modernes, cela mène à la discrimination, aux équipes homogènes et à de mauvaises décisions. Le biais opère sur plusieurs dimensions : démographie (âge, genre, ethnicité), éducation (mêmes écoles, diplômes), intérêts (loisirs, sports), style de communication et personnalité. En recrutement, il se manifeste par la préférence pour des candidats qui \"correspondent à la culture\" ou avec qui les interviewers ressentent une connexion naturelle. La recherche montre que les interviewers décident souvent en quelques secondes basé sur des similarités superficielles. Le biais d\\'affinité renforce les structures de pouvoir existantes et réduit la diversité. Il crée des chambres d\\'écho où des personnes similaires confirment les vues des autres. Le contrer nécessite des critères d\\'évaluation structurés, des panels d\\'entretien diversifiés, et chercher activement des personnes qui défient vos perspectives.",
    "example": "Hiring candidates from your alma mater. Feeling instant rapport with someone who shares your hobby. Trusting colleagues who communicate like you do.",
    "exampleFr": "Embaucher des candidats de votre ancienne université. Ressentir un rapport instantané avec quelqu\\'un qui partage vos loisirs. Faire confiance aux collègues qui communiquent comme vous.",
    "icon": "trending-up"
  },
  {
    "id": 9,
    "name": "Planning Fallacy",
    "nameFr": "Erreur de planification",
    "slug": "planning-fallacy",
    "summary": "Underestimating time, costs, and risks",
    "summaryFr": "Sous-estimer le temps, les coûts et les risques",
    "description": "The planning fallacy, coined by Kahneman and Tversky, is the systematic tendency to underestimate the time, costs, and risks of future actions while overestimating benefits. This bias persists despite repeated experience with projects exceeding their estimates. The Sydney Opera House, originally estimated at $7 million and 4 years, cost $102 million and took 16 years. This pattern repeats across construction, software development, and personal projects alike. The fallacy occurs because we plan using an \"inside view\"—focusing on the specific case and imagining everything going according to plan—rather than an \"outside view\" that considers base rates from similar past projects. We also underweight potential obstacles, assume tasks will proceed sequentially without delays, and fall prey to motivational biases (wanting projects to seem feasible). Reference class forecasting—looking at how long similar projects actually took—dramatically improves accuracy but requires overcoming the belief that \"this time is different.\" Adding buffer time helps, but research shows people consistently use buffers too small to account for actual variance. Successful planning requires treating past failures as informative rather than exceptional.",
    "descriptionFr": "L\\'erreur de planification, nommée par Kahneman et Tversky, est la tendance systématique à sous-estimer le temps, les coûts et les risques des actions futures tout en surestimant les bénéfices. Ce biais persiste malgré l\\'expérience répétée de projets dépassant leurs estimations. L\\'Opéra de Sydney, estimé à l\\'origine à 7 millions $ et 4 ans, a coûté 102 millions $ et pris 16 ans. Ce schéma se répète dans la construction, le développement logiciel et les projets personnels. L\\'erreur se produit parce que nous planifions avec une \"vue intérieure\"—nous concentrant sur le cas spécifique et imaginant que tout se passe selon le plan—plutôt qu\\'une \"vue extérieure\" qui considère les taux de base de projets passés similaires. Nous sous-pondérons aussi les obstacles potentiels, supposons que les tâches procéderont séquentiellement sans retards, et tombons dans les biais motivationnels (vouloir que les projets semblent faisables). La prévision par classe de référence—regarder combien de temps des projets similaires ont réellement pris—améliore dramatiquement la précision mais nécessite de surmonter la croyance que \"cette fois c\\'est différent.\" Ajouter du temps tampon aide, mais la recherche montre que les gens utilisent constamment des tampons trop petits.",
    "example": "Estimating renovation at $20,000 when similar projects cost $40,000. Thinking you\\'ll finish a report in 2 hours when it always takes 4. Underestimating moving time.",
    "exampleFr": "Estimer une rénovation à 20 000 $ quand des projets similaires ont coûté 40 000 $. Penser finir un rapport en 2 heures quand cela prend toujours 4. Sous-estimer le temps de déménagement.",
    "icon": "lightbulb"
  },
  {
    "id": 10,
    "name": "Loss Aversion",
    "nameFr": "Aversion à la perte",
    "slug": "loss-aversion",
    "summary": "Feeling losses more strongly than equivalent gains",
    "summaryFr": "Ressentir les pertes plus fortement que les gains équivalents",
    "description": "Loss aversion, a cornerstone of behavioral economics discovered by Kahneman and Tversky, is the tendency for the psychological pain of losing to be roughly twice as powerful as the pleasure of an equivalent gain. This asymmetry profoundly shapes human behavior. We\\'ll work harder to avoid losing $100 than to gain $100. Loss aversion explains why people hold losing investments too long (avoiding realizing the loss), why negotiations often fail (each side feels their concessions as losses), and why consumers respond more to \"don\\'t miss out\" than \"get this benefit.\" The bias extends beyond money—we\\'re loss averse about status, relationships, and possessions. The endowment effect (overvaluing what we own) stems from loss aversion: selling feels like losing. Loss aversion creates status quo bias: the potential losses from change loom larger than potential gains. It also explains risk-seeking behavior in the domain of losses—when facing a certain loss, people often gamble on worse odds hoping to avoid any loss. Marketers exploit this by framing messages in terms of what you\\'ll lose rather than gain. Overcoming loss aversion requires consciously reframing decisions, evaluating choices by final outcomes rather than changes, and recognizing that our emotional response to losses is disproportionate.",
    "descriptionFr": "L\\'aversion à la perte, pierre angulaire de l\\'économie comportementale découverte par Kahneman et Tversky, est la tendance à ce que la douleur psychologique de perdre soit environ deux fois plus puissante que le plaisir d\\'un gain équivalent. Cette asymétrie façonne profondément le comportement humain. Nous travaillerons plus dur pour éviter de perdre 100 $ que pour gagner 100 $. L\\'aversion à la perte explique pourquoi les gens gardent des investissements perdants trop longtemps (évitant de réaliser la perte), pourquoi les négociations échouent souvent (chaque partie ressent ses concessions comme des pertes), et pourquoi les consommateurs répondent plus à \"ne ratez pas\" qu\\'à \"obtenez ce bénéfice.\" Le biais s\\'étend au-delà de l\\'argent—nous sommes averses aux pertes de statut, relations et possessions. L\\'effet de dotation (surévaluer ce qu\\'on possède) découle de l\\'aversion à la perte : vendre semble comme perdre. Elle crée le biais du statu quo : les pertes potentielles du changement semblent plus grandes que les gains potentiels. Elle explique aussi le comportement de recherche de risque dans le domaine des pertes—face à une perte certaine, les gens parient souvent sur de pires probabilités espérant éviter toute perte. Surmonter l\\'aversion à la perte nécessite de recadrer consciemment les décisions et reconnaître que notre réponse émotionnelle aux pertes est disproportionnée.",
    "example": "Refusing to sell a declining stock to avoid \"realizing\" the loss. Rejecting a fair trade because what you give up feels more valuable. Working harder to keep $100 than to earn $100.",
    "exampleFr": "Refuser de vendre une action en baisse pour éviter de \"réaliser\" la perte. Rejeter un échange équitable parce que ce que vous cédez semble plus précieux. Travailler plus dur pour garder 100 $ que pour en gagner 100.",
    "icon": "compass"
  },
  {
    "id": 11,
    "name": "Hindsight Bias",
    "nameFr": "Biais rétrospectif",
    "slug": "hindsight-bias",
    "summary": "Believing past events were predictable",
    "summaryFr": "Croire que les événements passés étaient prévisibles",
    "description": "Hindsight bias, often called the \"I knew it all along\" phenomenon, is the tendency to perceive past events as having been more predictable than they actually were. Once we know an outcome, our brain retroactively adjusts our memory of what we believed beforehand, making the outcome seem inevitable. This cognitive distortion has profound implications for learning, accountability, and decision-making. It causes us to undervalue the difficulty of prediction and overestimate our own or others\\' ability to have foreseen events. In organizations, hindsight bias leads to unfair evaluations—judging decisions by outcomes rather than the information available at the time. Medical malpractice suits, financial audits, and historical analysis are all plagued by hindsight bias. It also prevents genuine learning from mistakes because we can\\'t accurately reconstruct what we actually knew or believed before the outcome. Research shows hindsight bias is remarkably resistant to correction; even warning people about it doesn\\'t eliminate it. Mitigating it requires documenting predictions and reasoning before outcomes are known, systematically reviewing what information was actually available at decision time, and acknowledging the genuine uncertainty that exists in complex situations.",
    "descriptionFr": "Le biais rétrospectif, souvent appelé le phénomène \"je le savais depuis le début,\" est la tendance à percevoir les événements passés comme ayant été plus prévisibles qu\\'ils ne l\\'étaient réellement. Une fois que nous connaissons un résultat, notre cerveau ajuste rétroactivement notre souvenir de ce que nous croyions auparavant, rendant le résultat inévitable. Cette distorsion cognitive a des implications profondes pour l\\'apprentissage, la responsabilité et la prise de décision. Elle nous fait sous-évaluer la difficulté de la prédiction et surestimer notre capacité ou celle des autres à avoir prévu les événements. Dans les organisations, le biais rétrospectif mène à des évaluations injustes—juger les décisions par les résultats plutôt que par l\\'information disponible au moment de la décision. Les poursuites pour faute médicale, les audits financiers et l\\'analyse historique sont tous affectés par ce biais. Il empêche aussi l\\'apprentissage véritable car nous ne pouvons pas reconstruire précisément ce que nous savions réellement avant le résultat. La recherche montre que le biais rétrospectif résiste remarquablement à la correction. L\\'atténuer nécessite de documenter les prédictions et le raisonnement avant que les résultats soient connus.",
    "example": "After a startup fails, believing the warning signs were obvious. Post-crisis, thinking \"everyone knew the market would crash.\" Second-guessing historical decisions with current knowledge.",
    "exampleFr": "Après l\\'échec d\\'une startup, croire que les signes avant-coureurs étaient évidents. Après une crise, penser que \"tout le monde savait que le marché allait s\\'effondrer.\" Remettre en question les décisions historiques avec les connaissances actuelles.",
    "icon": "alert-triangle"
  },
  {
    "id": 12,
    "name": "Bandwagon Effect",
    "nameFr": "Effet de mode",
    "slug": "bandwagon-effect",
    "summary": "Following the crowd without independent analysis",
    "summaryFr": "Suivre la foule sans analyse indépendante",
    "description": "The bandwagon effect is a powerful form of social conformity where people adopt beliefs, ideas, fads, or trends because others are doing so. This bias stems from our evolutionary need to belong to groups and the cognitive shortcut of using others\\' behavior as a signal of correctness. The more people who adopt a belief, the more \"proof\" it seems to have. This creates cascades and bubbles—in markets, politics, and culture—where momentum builds on itself regardless of underlying merit. Social media amplifies the bandwagon effect by making popular opinions highly visible and making dissent feel risky. In business, it manifests as following industry trends without strategic analysis, adopting technologies because competitors do, or implementing management fads. The bias explains phenomena from fashion trends to stock market bubbles to political polarization. Importantly, the bandwagon effect can lead to both rapid adoption of genuinely good ideas and to catastrophic collective errors. Resisting it requires developing independent judgment, seeking out dissenting voices, examining the actual evidence rather than counting votes, and asking whether you would hold the same opinion if it weren\\'t popular.",
    "descriptionFr": "L\\'effet de mode est une forme puissante de conformité sociale où les gens adoptent des croyances, idées, modes ou tendances parce que d\\'autres le font. Ce biais découle de notre besoin évolutionnaire d\\'appartenir à des groupes et du raccourci cognitif d\\'utiliser le comportement des autres comme signal de justesse. Plus les gens adoptent une croyance, plus elle semble avoir de \"preuves.\" Cela crée des cascades et des bulles—dans les marchés, la politique et la culture—où l\\'élan se construit sur lui-même indépendamment du mérite sous-jacent. Les réseaux sociaux amplifient l\\'effet de mode en rendant les opinions populaires très visibles et en faisant paraître la dissidence risquée. En affaires, cela se manifeste par le fait de suivre les tendances de l\\'industrie sans analyse stratégique, d\\'adopter des technologies parce que les concurrents le font, ou d\\'implémenter des modes de gestion. Le biais explique des phénomènes allant des tendances de mode aux bulles boursières à la polarisation politique. Résister nécessite de développer un jugement indépendant, de chercher des voix dissidentes, d\\'examiner les preuves réelles plutôt que de compter les votes, et de se demander si vous auriez la même opinion si elle n\\'était pas populaire.",
    "example": "Investing in a trending stock because everyone else is. Adopting a management methodology because it\\'s popular. Joining social media platforms because \"everyone is there.\"",
    "exampleFr": "Investir dans une action tendance parce que tout le monde le fait. Adopter une méthodologie de gestion parce qu\\'elle est populaire. Rejoindre des plateformes de réseaux sociaux parce que \"tout le monde y est.\"",
    "icon": "heart"
  },
  {
    "id": 13,
    "name": "Recency Bias",
    "nameFr": "Biais de récence",
    "slug": "recency-bias",
    "summary": "Overweighting recent events over historical patterns",
    "summaryFr": "Surpondérer les événements récents par rapport aux schémas historiques",
    "description": "Recency bias is the cognitive tendency to weight recent events or information more heavily than earlier data when forming judgments. This bias arises because recent memories are more vivid, accessible, and emotionally charged. In performance evaluations, it causes managers to disproportionately weight the last few weeks, ignoring months of prior work. In investing, recent market performance dominates expectations, leading to buying high after rallies and selling low after crashes. The bias affects hiring (emphasizing recent interview impressions), relationships (letting recent conflicts overshadow years of positive history), and strategic planning (extrapolating recent trends indefinitely). Recency bias is particularly dangerous in environments with high variability or mean reversion, where recent performance is a poor predictor of future results. It contributes to boom-bust cycles and prevents learning from historical patterns. Counteracting recency bias requires systematic data collection over longer periods, structured evaluation frameworks that force consideration of historical performance, and deliberately asking \"is this recent trend representative of the longer pattern?\"",
    "descriptionFr": "Le biais de récence est la tendance cognitive à accorder plus de poids aux événements ou informations récents qu\\'aux données antérieures lors de la formation de jugements. Ce biais survient parce que les souvenirs récents sont plus vifs, accessibles et chargés émotionnellement. Dans les évaluations de performance, il amène les managers à surpondérer les dernières semaines, ignorant des mois de travail antérieur. En investissement, la performance récente du marché domine les attentes, menant à acheter haut après les hausses et vendre bas après les baisses. Le biais affecte le recrutement (emphase sur les impressions récentes d\\'entretien), les relations (laisser les conflits récents éclipser des années d\\'histoire positive), et la planification stratégique (extrapoler les tendances récentes indéfiniment). Le biais de récence est particulièrement dangereux dans les environnements à haute variabilité ou avec retour à la moyenne, où la performance récente prédit mal les résultats futurs. Le contrer nécessite une collecte systématique de données sur de plus longues périodes et des cadres d\\'évaluation structurés qui forcent la considération de la performance historique.",
    "example": "Judging an employee mostly on their last month. Expecting stock trends to continue after a recent rally or crash. Forgetting years of good service after one bad experience.",
    "exampleFr": "Juger un employé principalement sur son dernier mois. S\\'attendre à ce que les tendances boursières continuent après une hausse ou baisse récente. Oublier des années de bon service après une mauvaise expérience.",
    "icon": "bookmark"
  },
  {
    "id": 14,
    "name": "Framing Effect",
    "nameFr": "Effet de cadrage",
    "slug": "framing-effect",
    "summary": "Being influenced by how information is presented",
    "summaryFr": "Être influencé par la façon dont l\\'information est présentée",
    "description": "The framing effect demonstrates that logically equivalent information can lead to different decisions depending on how it\\'s presented. This violates the economic assumption that rational agents should respond to substance, not presentation. Kahneman and Tversky\\'s famous \"Asian disease problem\" showed that people choose risk-averse options when outcomes are framed as gains but risk-seeking options when framed as losses—even when the mathematical outcomes are identical. Framing operates through several mechanisms: positive vs. negative emphasis, absolute vs. relative numbers, narrow vs. broad context, and order effects. Marketers, politicians, and negotiators exploit framing constantly: \"95% fat-free\" versus \"5% fat,\" \"save $10\" versus \"avoid losing $10,\" \"3 out of 4 dentists recommend\" versus \"1 in 4 dentists don\\'t recommend.\" Medical decisions are particularly susceptible—patients make different treatment choices based on whether outcomes are presented as survival rates or mortality rates. Defense against framing requires actively reframing information in multiple ways, asking \"how would my decision change if this were presented differently?\", and focusing on absolute numbers and final states rather than relative changes or selective statistics.",
    "descriptionFr": "L\\'effet de cadrage démontre que des informations logiquement équivalentes peuvent mener à des décisions différentes selon leur présentation. Cela viole l\\'hypothèse économique que les agents rationnels devraient répondre à la substance, pas à la présentation. Le célèbre \"problème de la maladie asiatique\" de Kahneman et Tversky a montré que les gens choisissent des options adverses au risque quand les résultats sont cadrés comme des gains mais cherchent le risque quand ils sont cadrés comme des pertes—même quand les résultats mathématiques sont identiques. Le cadrage opère par plusieurs mécanismes : emphase positive vs négative, nombres absolus vs relatifs, contexte étroit vs large, et effets d\\'ordre. Les marketeurs, politiciens et négociateurs exploitent constamment le cadrage : \"95% sans matière grasse\" versus \"5% de matière grasse,\" \"économisez 10$\" versus \"évitez de perdre 10$.\" Les décisions médicales sont particulièrement susceptibles—les patients font des choix de traitement différents selon que les résultats sont présentés comme taux de survie ou taux de mortalité. La défense contre le cadrage nécessite de recadrer activement l\\'information de multiples façons.",
    "example": "\"90% success rate\" sounds better than \"10% failure rate.\" \"Save $50\" is more attractive than \"Spend $200 instead of $250.\" \"1 in 1000 risk\" feels different than \"0.1% chance.\"",
    "exampleFr": "\"90% de taux de réussite\" semble mieux que \"10% de taux d\\'échec.\" \"Économisez 50$\" est plus attrayant que \"Dépensez 200$ au lieu de 250$.\" \"1 risque sur 1000\" semble différent de \"0,1% de chance.\"",
    "icon": "filter"
  },
  {
    "id": 15,
    "name": "Fundamental Attribution Error",
    "nameFr": "Erreur fondamentale d\\'attribution",
    "slug": "attribution-error",
    "summary": "Attributing others\\' behavior to character, not circumstances",
    "summaryFr": "Attribuer le comportement des autres à leur caractère, pas aux circonstances",
    "description": "The fundamental attribution error (FAE), also called correspondence bias, is the tendency to overattribute others\\' behavior to their character or personality while underweighting situational factors, and doing the opposite for ourselves. When someone cuts us off in traffic, we assume they\\'re a jerk; when we cut someone off, we had a good reason. This asymmetry stems from differences in information access—we know our own situations but must infer others\\'—and from perceptual focus—when observing others, they are the figure and the situation is background. The FAE has profound implications for how we judge, manage, and interact with people. In workplaces, it leads managers to attribute poor performance to character flaws rather than examining systems, resources, or circumstances. It fuels stereotyping and prejudice by assuming group differences reflect inherent traits rather than historical circumstances. Cross-cultural research shows the FAE is stronger in individualistic Western cultures than in collectivist Eastern ones, suggesting it\\'s partly cultural. Correcting for FAE requires deliberately considering what situational factors might explain behavior, imagining yourself in the other person\\'s position, and seeking information about context before making character judgments.",
    "descriptionFr": "L\\'erreur fondamentale d\\'attribution (EFA), aussi appelée biais de correspondance, est la tendance à surattribuer le comportement des autres à leur caractère ou personnalité tout en sous-pondérant les facteurs situationnels, et à faire l\\'inverse pour nous-mêmes. Quand quelqu\\'un nous coupe la route, nous supposons que c\\'est un imbécile ; quand nous le faisons, nous avions une bonne raison. Cette asymétrie découle des différences d\\'accès à l\\'information—nous connaissons nos propres situations mais devons inférer celles des autres—et du focus perceptuel—en observant les autres, ils sont la figure et la situation est l\\'arrière-plan. L\\'EFA a des implications profondes sur la façon dont nous jugeons, gérons et interagissons avec les gens. Dans les entreprises, elle amène les managers à attribuer les mauvaises performances aux défauts de caractère plutôt qu\\'à examiner les systèmes, ressources ou circonstances. Elle alimente les stéréotypes et préjugés en supposant que les différences de groupe reflètent des traits inhérents plutôt que des circonstances historiques. Corriger l\\'EFA nécessite de considérer délibérément quels facteurs situationnels pourraient expliquer le comportement et d\\'imaginer vous-même dans la position de l\\'autre personne.",
    "example": "Thinking a colleague is lazy when they miss a deadline, without considering personal issues. Assuming a rude cashier has a bad personality, not a bad day.",
    "exampleFr": "Penser qu\\'un collègue est paresseux quand il manque une date limite, sans considérer ses problèmes personnels. Supposer qu\\'un caissier impoli a une mauvaise personnalité, pas une mauvaise journée.",
    "icon": "sun"
  },
  {
    "id": 16,
    "name": "Optimism Bias",
    "nameFr": "Biais d\\'optimisme",
    "slug": "optimism-bias",
    "summary": "Believing bad things are less likely to happen to you",
    "summaryFr": "Croire que les mauvaises choses sont moins susceptibles de vous arriver",
    "description": "Optimism bias is the systematic tendency to believe that we personally are less likely to experience negative events and more likely to experience positive ones compared to others. About 80% of people display this bias. We underestimate our chances of getting divorced, having a car accident, or developing cancer, while overestimating our chances of living long, having talented children, and career success. This bias appears to be neurologically hardwired—brain imaging shows reduced processing of negative information about future outcomes. Evolutionarily, optimism bias may promote action and persistence; depressed individuals often have more accurate (but less adaptive) predictions. However, the bias causes significant problems: underinsurance, inadequate savings, risky health behaviors, and poor project planning. The planning fallacy is partly driven by optimism bias. In business, it leads entrepreneurs to underestimate competition and overestimate demand. Optimism bias is resistant to correction but can be partially mitigated through \"reference class forecasting\" (comparing to statistical base rates), pre-mortem analysis (imagining what could go wrong), and explicitly considering the perspective of a neutral observer who doesn\\'t share your motivated optimism.",
    "descriptionFr": "Le biais d\\'optimisme est la tendance systématique à croire que nous personnellement sommes moins susceptibles de vivre des événements négatifs et plus susceptibles de vivre des événements positifs par rapport aux autres. Environ 80% des gens affichent ce biais. Nous sous-estimons nos chances de divorcer, d\\'avoir un accident de voiture ou de développer un cancer, tout en surestimant nos chances de vivre longtemps, d\\'avoir des enfants talentueux et de réussir professionnellement. Ce biais semble être câblé neurologiquement—l\\'imagerie cérébrale montre un traitement réduit des informations négatives sur les résultats futurs. Évolutivement, le biais d\\'optimisme peut promouvoir l\\'action et la persistance ; les individus déprimés ont souvent des prédictions plus précises (mais moins adaptatives). Cependant, le biais cause des problèmes significatifs : sous-assurance, épargne inadéquate, comportements de santé risqués et mauvaise planification de projets. L\\'erreur de planification est partiellement motivée par le biais d\\'optimisme. En affaires, il amène les entrepreneurs à sous-estimer la concurrence et surestimer la demande. Il peut être partiellement atténué par la prévision par classe de référence et l\\'analyse pré-mortem (imaginer ce qui pourrait mal tourner).",
    "example": "Starting a business believing you\\'ll succeed despite most failing. Smoking while thinking \"cancer happens to others.\" Not saving for retirement assuming things will work out.",
    "exampleFr": "Créer une entreprise en croyant réussir malgré que la plupart échouent. Fumer en pensant \"le cancer arrive aux autres.\" Ne pas épargner pour la retraite en supposant que tout ira bien.",
    "icon": "moon"
  },
  {
    "id": 17,
    "name": "Pessimism Bias",
    "nameFr": "Biais de pessimisme",
    "slug": "pessimism-bias",
    "summary": "Expecting negative outcomes even when unlikely",
    "summaryFr": "S\\'attendre à des résultats négatifs même lorsqu\\'ils sont improbables",
    "description": "Pessimism bias is the tendency to overestimate the probability and severity of negative outcomes while underestimating positive possibilities. While less common than optimism bias, it\\'s prevalent among those with depression, anxiety, or past trauma, and can also be situationally triggered by recent negative experiences or threatening contexts. Pessimism bias has a protective function—preparing for the worst—but at significant cost. It leads to excessive risk aversion, missed opportunities, and self-fulfilling prophecies where negative expectations reduce effort and thus produce negative outcomes. In organizations, it manifests as resistance to innovation, reluctance to pursue growth, and paralysis in decision-making. Pessimistic leaders can dampen team morale and prevent the calculated risks necessary for success. The bias is often masked as \"realism\" or \"being cautious,\" making it harder to recognize. Unlike optimism bias, pessimism bias is associated with poorer mental and physical health outcomes. Correcting it requires examining evidence objectively, tracking prediction accuracy over time (pessimists are often surprised by positive outcomes), practicing cognitive reframing, and deliberately considering best-case scenarios alongside worst-case ones rather than focusing exclusively on potential negatives.",
    "descriptionFr": "Le biais de pessimisme est la tendance à surestimer la probabilité et la sévérité des résultats négatifs tout en sous-estimant les possibilités positives. Bien que moins courant que le biais d\\'optimisme, il est prévalent chez ceux qui souffrent de dépression, d\\'anxiété ou de traumatismes passés, et peut aussi être déclenché situationnellement par des expériences négatives récentes ou des contextes menaçants. Le biais de pessimisme a une fonction protectrice—se préparer au pire—mais à un coût significatif. Il mène à une aversion au risque excessive, des opportunités manquées et des prophéties auto-réalisatrices où les attentes négatives réduisent l\\'effort et produisent ainsi des résultats négatifs. Dans les organisations, il se manifeste par la résistance à l\\'innovation, la réticence à poursuivre la croissance et la paralysie dans la prise de décision. Les leaders pessimistes peuvent décourager le moral de l\\'équipe. Le biais est souvent masqué comme \"réalisme\" ou \"être prudent,\" le rendant plus difficile à reconnaître. Le corriger nécessite d\\'examiner les preuves objectivement, de suivre la précision des prédictions dans le temps et de considérer délibérément les meilleurs scénarios aux côtés des pires.",
    "example": "Refusing to apply for a dream job because you\\'re convinced you won\\'t get it. Not starting a project assuming it will fail. Avoiding relationships expecting to be hurt.",
    "exampleFr": "Refuser de postuler pour un emploi de rêve parce que vous êtes convaincu de ne pas l\\'obtenir. Ne pas démarrer un projet en supposant qu\\'il échouera. Éviter les relations en s\\'attendant à être blessé.",
    "icon": "star"
  },
  {
    "id": 18,
    "name": "Self-Serving Bias",
    "nameFr": "Biais d\\'auto-complaisance",
    "slug": "self-serving-bias",
    "summary": "Taking credit for success, blaming others for failure",
    "summaryFr": "S\\'attribuer les succès, blâmer les autres pour les échecs",
    "description": "Self-serving bias is the pervasive tendency to attribute successes to internal factors (our skill, effort, intelligence) while attributing failures to external factors (bad luck, others\\' mistakes, unfair circumstances). This asymmetric pattern protects self-esteem and maintains a positive self-image. Research shows it operates across cultures, though more strongly in individualistic societies. The bias has both cognitive and motivational components: we genuinely process information differently when it affects us versus others, and we\\'re motivated to see ourselves favorably. In organizations, self-serving bias creates conflict and prevents learning. Managers credit themselves for team successes but blame team members or market conditions for failures. Teams fall into blame cycles where everyone attributes problems to others. The bias distorts performance reviews, with each party having a skewed view of contributions. It also inflates confidence in future success—past wins reinforce belief in our abilities while past losses don\\'t update our self-assessment. Overcoming self-serving bias requires systematic accountability, seeking feedback from others, documenting the role of luck and circumstance in successes, and genuinely examining one\\'s contribution to failures.",
    "descriptionFr": "Le biais d\\'auto-complaisance est la tendance omniprésente à attribuer les succès à des facteurs internes (notre compétence, effort, intelligence) tout en attribuant les échecs à des facteurs externes (malchance, erreurs des autres, circonstances injustes). Ce schéma asymétrique protège l\\'estime de soi et maintient une image de soi positive. La recherche montre qu\\'il opère à travers les cultures, bien que plus fortement dans les sociétés individualistes. Le biais a des composantes cognitives et motivationnelles : nous traitons véritablement l\\'information différemment quand elle nous affecte versus les autres, et nous sommes motivés à nous voir favorablement. Dans les organisations, le biais d\\'auto-complaisance crée des conflits et empêche l\\'apprentissage. Les managers s\\'attribuent les succès de l\\'équipe mais blâment les membres ou les conditions du marché pour les échecs. Les équipes tombent dans des cycles de blâme où chacun attribue les problèmes aux autres. Le biais déforme les évaluations de performance. Il gonfle aussi la confiance dans le succès futur—les victoires passées renforcent la croyance en nos capacités tandis que les pertes passées ne mettent pas à jour notre auto-évaluation. Le surmonter nécessite une responsabilisation systématique et chercher des retours des autres.",
    "example": "When a project succeeds, believing it was your leadership. When it fails, blaming market conditions. Attributing a win to skill but a loss to bad luck.",
    "exampleFr": "Quand un projet réussit, croire que c\\'était grâce à votre leadership. Quand il échoue, blâmer les conditions du marché. Attribuer une victoire à la compétence mais une défaite à la malchance.",
    "icon": "coffee"
  },
  {
    "id": 19,
    "name": "Dunning-Kruger Effect",
    "nameFr": "Effet Dunning-Kruger",
    "slug": "dunning-kruger-effect",
    "summary": "Novices overestimate their competence; experts underestimate",
    "summaryFr": "Les novices surestiment leur compétence ; les experts sous-estiment",
    "description": "The Dunning-Kruger effect, documented by psychologists David Dunning and Justin Kruger in 1999, describes a cognitive bias where people with low ability in a domain overestimate their competence, while highly skilled individuals tend to underestimate theirs. The core insight is that the skills needed to perform well in a domain are often the same skills needed to recognize competence in that domain. Incompetent individuals lack the metacognitive ability to recognize their own incompetence. This creates the \"peak of Mount Stupid\"—a point of high confidence with low skill—followed by the \"valley of despair\" as learning reveals one\\'s limitations, eventually reaching a more calibrated \"plateau of sustainability.\" The effect explains why beginners often act with misplaced confidence while experts hedge and qualify their statements. In organizations, it means that those least qualified to make decisions may be the most confident about making them. The effect is amplified by the fact that confident (though wrong) people are often more persuasive. Counteracting it requires creating cultures that value admitting uncertainty, seeking feedback from more knowledgeable others, and developing metacognitive skills to accurately assess one\\'s own competence.",
    "descriptionFr": "L\\'effet Dunning-Kruger, documenté par les psychologues David Dunning et Justin Kruger en 1999, décrit un biais cognitif où les personnes à faible capacité dans un domaine surestiment leur compétence, tandis que les individus très compétents tendent à sous-estimer la leur. L\\'idée centrale est que les compétences nécessaires pour bien performer dans un domaine sont souvent les mêmes que celles nécessaires pour reconnaître la compétence dans ce domaine. Les individus incompétents manquent de la capacité métacognitive pour reconnaître leur propre incompétence. Cela crée le \"pic de Mont Stupide\"—un point de haute confiance avec faible compétence—suivi par la \"vallée du désespoir\" quand l\\'apprentissage révèle ses limites, atteignant finalement un \"plateau de durabilité\" plus calibré. L\\'effet explique pourquoi les débutants agissent souvent avec une confiance mal placée tandis que les experts nuancent et qualifient leurs déclarations. Dans les organisations, cela signifie que ceux les moins qualifiés pour prendre des décisions peuvent être les plus confiants à les prendre. L\\'effet est amplifié par le fait que les personnes confiantes (bien que fausses) sont souvent plus persuasives. Le contrer nécessite de créer des cultures qui valorisent l\\'admission de l\\'incertitude.",
    "example": "A new manager confidently making radical changes without understanding complexity. A beginner chess player overestimating their rating. First-time investors confident they can beat the market.",
    "exampleFr": "Un nouveau manager faisant des changements radicaux avec confiance sans comprendre la complexité. Un joueur d\\'échecs débutant surestimant son classement. Des investisseurs débutants confiants de pouvoir battre le marché.",
    "icon": "key"
  },
  {
    "id": 20,
    "name": "Negativity Bias",
    "nameFr": "Biais de négativité",
    "slug": "negativity-bias",
    "summary": "Giving more weight to negative experiences than positive ones",
    "summaryFr": "Accorder plus d\\'importance aux expériences négatives qu\\'aux positives",
    "description": "Negativity bias is the deep-rooted psychological tendency to register, dwell on, and be more influenced by negative stimuli than positive ones of equal magnitude. Research suggests negative events are processed more thoroughly than positive ones, produce stronger emotional responses, and are remembered more vividly. Evolutionarily, this makes sense: failing to notice a predator (negative) was more costly than missing a food source (positive). The ratio varies by context, but research suggests we need roughly 3-5 positive experiences to balance one negative one in relationships and work environments. Negativity bias affects attention (threats capture focus faster), learning (we learn more from punishment than reward), memory (traumatic events are indelible), decision-making (avoiding loss outweighs seeking gain), and impression formation (one negative trait can override many positive ones). In organizations, it means criticism lands harder than praise, and one toxic interaction can undo months of positive culture-building. Media exploits negativity bias because negative news captures more attention. Combating it requires conscious effort to notice and savor positive experiences, maintaining a balanced perspective by actively counting positives, and creating systems that deliberately amplify positive feedback.",
    "descriptionFr": "Le biais de négativité est la tendance psychologique profondément enracinée à enregistrer, s\\'attarder sur et être plus influencé par les stimuli négatifs que les positifs de magnitude égale. La recherche suggère que les événements négatifs sont traités plus minutieusement que les positifs, produisent des réponses émotionnelles plus fortes et sont mémorisés plus vivement. Évolutivement, cela a du sens : ne pas remarquer un prédateur (négatif) était plus coûteux que rater une source de nourriture (positif). Le ratio varie selon le contexte, mais la recherche suggère que nous avons besoin d\\'environ 3-5 expériences positives pour équilibrer une négative dans les relations et environnements de travail. Le biais de négativité affecte l\\'attention (les menaces captent le focus plus vite), l\\'apprentissage (nous apprenons plus de la punition que de la récompense), la mémoire (les événements traumatiques sont indélébiles), la prise de décision (éviter la perte l\\'emporte sur chercher le gain), et la formation d\\'impression (un trait négatif peut éclipser plusieurs positifs). Dans les organisations, cela signifie que la critique frappe plus fort que l\\'éloge. Le combattre nécessite un effort conscient pour remarquer et savourer les expériences positives.",
    "example": "A single critical review outweighing ten positive reviews. Remembering one insult longer than many compliments. News focusing on disasters rather than progress.",
    "exampleFr": "Un seul avis critique l\\'emportant sur dix avis positifs. Se souvenir d\\'une insulte plus longtemps que de nombreux compliments. Les nouvelles se concentrant sur les catastrophes plutôt que les progrès.",
    "icon": "brain"
  },
  {
    "id": 21,
    "name": "Endowment Effect",
    "nameFr": "Effet de dotation",
    "slug": "endowment-effect",
    "summary": "Overvaluing things because you own them",
    "summaryFr": "Surévaluer les choses parce qu\\'elles vous appartiennent",
    "description": "The endowment effect, first demonstrated by Richard Thaler, is the phenomenon where people value objects they own more highly than identical objects they don\\'t own. In classic experiments, people given coffee mugs demanded about twice as much to sell them as others were willing to pay to buy them—despite the mugs being assigned randomly. This effect stems from loss aversion: selling feels like losing, and losses hurt more than equivalent gains feel good. The endowment effect extends beyond physical objects to ideas, strategies, and relationships. In negotiations, each party may genuinely believe their position is more valuable, making compromise difficult. In organizations, it causes resistance to changing processes or strategies we\\'ve invested in. It explains why people keep possessions they never use, why companies maintain failing product lines, and why people demand more compensation for giving up a benefit than they\\'d pay to acquire it. The effect increases with ownership duration and emotional attachment. Counteracting it requires deliberately imagining not owning the object and asking what you\\'d pay to acquire it, seeking objective market valuations, and recognizing that selling something isn\\'t losing—it\\'s trading for something of equal or greater value.",
    "descriptionFr": "L\\'effet de dotation, démontré pour la première fois par Richard Thaler, est le phénomène où les gens valorisent les objets qu\\'ils possèdent plus que des objets identiques qu\\'ils ne possèdent pas. Dans des expériences classiques, les personnes à qui on a donné des tasses demandaient environ deux fois plus pour les vendre que ce que d\\'autres étaient prêts à payer pour les acheter—malgré que les tasses aient été attribuées au hasard. Cet effet découle de l\\'aversion à la perte : vendre ressemble à perdre, et les pertes font plus mal que les gains équivalents ne font plaisir. L\\'effet de dotation s\\'étend au-delà des objets physiques aux idées, stratégies et relations. Dans les négociations, chaque partie peut sincèrement croire que sa position est plus précieuse, rendant le compromis difficile. Dans les organisations, il cause une résistance à changer les processus ou stratégies dans lesquels nous avons investi. Il explique pourquoi les gens gardent des possessions qu\\'ils n\\'utilisent jamais, pourquoi les entreprises maintiennent des lignes de produits en échec. L\\'effet augmente avec la durée de possession et l\\'attachement émotionnel. Le contrer nécessite d\\'imaginer délibérément ne pas posséder l\\'objet et se demander ce qu\\'on paierait pour l\\'acquérir.",
    "example": "Refusing a fair offer for your car because it\\'s \"yours.\" Demanding higher prices for items you\\'re selling than you\\'d pay to buy them. Overvaluing your company\\'s stock.",
    "exampleFr": "Refuser une offre équitable pour votre voiture parce qu\\'elle est \"la vôtre.\" Demander des prix plus élevés pour les articles que vous vendez que ce que vous paieriez pour les acheter. Surévaluer les actions de votre entreprise.",
    "icon": "target"
  },
  {
    "id": 22,
    "name": "Gambler\\'s Fallacy",
    "nameFr": "Sophisme du joueur",
    "slug": "gamblers-fallacy",
    "summary": "Believing past random events affect future probabilities",
    "summaryFr": "Croire que les événements aléatoires passés affectent les probabilités futures",
    "description": "The gambler\\'s fallacy is the mistaken belief that past random events affect the probability of future random events. After a coin lands heads five times in a row, people believe tails is \"due\"—but each flip remains 50/50. The fallacy stems from the \"representativeness heuristic\": we expect short sequences to look like the long-run probability, so a streak seems unrepresentative and due for correction. This belief in a \"balancing force\" in random processes is deeply intuitive but mathematically false. The famous Monte Carlo casino incident of 1913, where black came up 26 times in a row at roulette, saw gamblers lose millions betting on red, convinced it was overdue. In business, the fallacy manifests as expecting a string of successes to continue (hot hand fallacy—the inverse) or expecting failure to reverse without changing the underlying process. Investment decisions are particularly vulnerable: assuming a stock that dropped must rebound, or that a fund\\'s recent performance predicts future returns. The antidote is understanding true randomness, distinguishing between independent events (each has the same probability) and dependent sequences (where history actually matters), and evaluating base rates rather than patterns in small samples.",
    "descriptionFr": "Le sophisme du joueur est la croyance erronée que les événements aléatoires passés affectent la probabilité des événements aléatoires futurs. Après qu\\'une pièce tombe sur face cinq fois de suite, les gens croient que pile est \"dû\"—mais chaque lancer reste à 50/50. Le sophisme découle de l\\'\"heuristique de représentativité\" : nous nous attendons à ce que les courtes séquences ressemblent à la probabilité à long terme, donc une série semble non représentative et due pour correction. Cette croyance en une \"force d\\'équilibrage\" dans les processus aléatoires est profondément intuitive mais mathématiquement fausse. Le célèbre incident du casino de Monte Carlo de 1913, où le noir est sorti 26 fois de suite à la roulette, a vu les joueurs perdre des millions en pariant sur le rouge, convaincus qu\\'il était en retard. En affaires, le sophisme se manifeste en s\\'attendant à ce qu\\'une série de succès continue ou en s\\'attendant à ce que l\\'échec s\\'inverse sans changer le processus sous-jacent. L\\'antidote est de comprendre la vraie aléatoireté, distinguer entre les événements indépendants et les séquences dépendantes, et évaluer les taux de base plutôt que les modèles dans de petits échantillons.",
    "example": "After three failed hires, believing \"the next one must be good.\" Betting on red after a streak of black. Assuming a stock must rebound after falling.",
    "exampleFr": "Après trois recrutements ratés, croire que \"le prochain doit être bon.\" Parier sur le rouge après une série de noir. Supposer qu\\'une action doit rebondir après avoir chuté.",
    "icon": "eye"
  },
  {
    "id": 23,
    "name": "Authority Bias",
    "nameFr": "Biais d\\'autorité",
    "slug": "authority-bias",
    "summary": "Trusting authority figures without questioning",
    "summaryFr": "Faire confiance aux figures d\\'autorité sans questionner",
    "description": "Authority bias is the tendency to attribute greater accuracy and trustworthiness to the opinions of authority figures, regardless of actual expertise in the relevant domain. Stanley Milgram\\'s famous obedience experiments dramatically demonstrated how people follow authority even to apparently harmful actions. The bias developed as an adaptive shortcut: deferring to those with knowledge or experience saves time and often produces good outcomes. However, it becomes problematic when authority in one domain is assumed to transfer to others (a successful CEO opining on medicine), when titles or credentials are mistaken for competence, or when authority suppresses necessary dissent. In organizations, authority bias creates \"HiPPO\" decision-making (Highest Paid Person\\'s Opinion wins), silences valuable input from lower-ranking employees, and allows errors to propagate when no one questions leadership. The medical field has studied how authority bias leads junior staff to not challenge senior doctors\\' obvious mistakes. Marketing exploits this with \"experts recommend\" messaging. Resisting authority bias requires evaluating arguments on their merits rather than their source, creating psychological safety for dissent, and distinguishing between relevant expertise and general authority.",
    "descriptionFr": "Le biais d\\'autorité est la tendance à attribuer une plus grande exactitude et fiabilité aux opinions des figures d\\'autorité, indépendamment de l\\'expertise réelle dans le domaine pertinent. Les célèbres expériences d\\'obéissance de Stanley Milgram ont dramatiquement démontré comment les gens suivent l\\'autorité même vers des actions apparemment nuisibles. Le biais s\\'est développé comme raccourci adaptatif : déférer à ceux qui ont des connaissances ou de l\\'expérience économise du temps et produit souvent de bons résultats. Cependant, il devient problématique quand l\\'autorité dans un domaine est supposée se transférer à d\\'autres (un PDG à succès donnant son avis sur la médecine), quand les titres ou références sont confondus avec la compétence, ou quand l\\'autorité supprime la dissidence nécessaire. Dans les organisations, le biais d\\'autorité crée la prise de décision \"HiPPO\" (l\\'Opinion de la Personne la Mieux Payée gagne), fait taire les contributions précieuses des employés de rang inférieur, et permet aux erreurs de se propager quand personne ne questionne la direction. Résister au biais d\\'autorité nécessite d\\'évaluer les arguments sur leurs mérites plutôt que leur source et de créer une sécurité psychologique pour la dissidence.",
    "example": "Following a CEO\\'s strategic advice without analysis because of their title. Accepting a doctor\\'s opinion on economics because they\\'re a doctor. Not questioning a manager\\'s clearly flawed plan.",
    "exampleFr": "Suivre les conseils stratégiques d\\'un PDG sans analyse en raison de son titre. Accepter l\\'opinion d\\'un médecin sur l\\'économie parce qu\\'il est médecin. Ne pas questionner le plan clairement défectueux d\\'un manager.",
    "icon": "scale"
  },
  {
    "id": 24,
    "name": "Outcome Bias",
    "nameFr": "Biais de résultat",
    "slug": "outcome-bias",
    "summary": "Judging decisions by their results, not their quality",
    "summaryFr": "Juger les décisions par leurs résultats, pas leur qualité",
    "description": "Outcome bias is the tendency to evaluate the quality of a decision based on its outcome rather than on the information available and reasoning applied at the time the decision was made. A good decision can have a bad outcome due to unforeseeable events, and a bad decision can succeed through luck. Yet we consistently judge decision-makers by results. This creates several problems: it punishes thoughtful risk-taking when luck doesn\\'t cooperate, it rewards reckless decisions that happen to succeed, and it prevents learning the right lessons from experience. In medicine, a surgeon who makes the correct choice given available information but loses a patient may be judged more harshly than one who made a questionable call but got lucky. In investing, fund managers are rated by returns without accounting for the risks taken to achieve them. Outcome bias is closely related to hindsight bias—once we know the outcome, it colors our judgment of the decision process. Combating outcome bias requires separating decision quality from outcome quality, evaluating decisions based on process and reasoning at the time, creating \"decision journals\" that document thinking before outcomes are known, and accepting that in uncertain environments, good decisions will sometimes fail.",
    "descriptionFr": "Le biais de résultat est la tendance à évaluer la qualité d\\'une décision en fonction de son résultat plutôt que des informations disponibles et du raisonnement appliqué au moment où la décision a été prise. Une bonne décision peut avoir un mauvais résultat à cause d\\'événements imprévisibles, et une mauvaise décision peut réussir par chance. Pourtant, nous jugeons constamment les décideurs par les résultats. Cela crée plusieurs problèmes : cela punit la prise de risque réfléchie quand la chance ne coopère pas, récompense les décisions imprudentes qui réussissent par hasard, et empêche d\\'apprendre les bonnes leçons de l\\'expérience. En médecine, un chirurgien qui fait le bon choix compte tenu des informations disponibles mais perd un patient peut être jugé plus sévèrement qu\\'un autre qui a fait un choix discutable mais a eu de la chance. En investissement, les gestionnaires de fonds sont notés par les rendements sans tenir compte des risques pris pour les atteindre. Combattre le biais de résultat nécessite de séparer la qualité de la décision de la qualité du résultat, d\\'évaluer les décisions basées sur le processus et le raisonnement au moment de la prise de décision, et d\\'accepter que dans les environnements incertains, les bonnes décisions échoueront parfois.",
    "example": "Praising a risky investment that happened to pay off. Firing a manager whose good decision had a bad outcome due to luck. Celebrating a reckless gamble that succeeded.",
    "exampleFr": "Louer un investissement risqué qui a par hasard été rentable. Licencier un manager dont la bonne décision a eu un mauvais résultat à cause de la malchance. Célébrer un pari imprudent qui a réussi.",
    "icon": "clock"
  },
  {
    "id": 25,
    "name": "Survivorship Bias",
    "nameFr": "Biais du survivant",
    "slug": "survivorship-bias",
    "summary": "Focusing on successes while ignoring failures",
    "summaryFr": "Se concentrer sur les succès tout en ignorant les échecs",
    "description": "Survivorship bias is the logical error of concentrating on successful outcomes that passed a selection process while overlooking failures that are less visible. The classic example comes from World War II: engineers wanted to armor the parts of returning aircraft that showed the most bullet holes, until statistician Abraham Wald pointed out that the holes showed where planes could be hit and still return—the missing planes were hit elsewhere. This bias pervades business advice, where we study successful companies without equal attention to failed ones that did the same things. \"Follow your passion\" is survivorship-biased advice: we hear from passionate people who succeeded, not the equally passionate who failed. Music, art, startups—every field has visible successes that mask an invisible graveyard of failures. The bias leads to overestimating the probability of success and misattributing causes. A strategy that works for one visible success might have failed for thousands of invisible cases. Correcting survivorship bias requires actively seeking out failure cases, understanding selection mechanisms, calculating base rates of success, and asking \"what would I expect to see if success were purely random?\" to distinguish skill from luck.",
    "descriptionFr": "Le biais du survivant est l\\'erreur logique de se concentrer sur les résultats réussis qui ont passé un processus de sélection tout en négligeant les échecs moins visibles. L\\'exemple classique vient de la Seconde Guerre mondiale : les ingénieurs voulaient renforcer les parties des avions qui montraient le plus d\\'impacts de balles, jusqu\\'à ce que le statisticien Abraham Wald souligne que les impacts montraient où les avions pouvaient être touchés et quand même revenir—les avions manquants avaient été touchés ailleurs. Ce biais imprègne les conseils business, où nous étudions les entreprises à succès sans attention égale à celles qui ont échoué en faisant les mêmes choses. \"Suivez votre passion\" est un conseil biaisé par la survie : nous entendons les gens passionnés qui ont réussi, pas les également passionnés qui ont échoué. Musique, art, startups—chaque domaine a des succès visibles qui masquent un cimetière invisible d\\'échecs. Le biais mène à surestimer la probabilité de succès et à mal attribuer les causes. Corriger le biais du survivant nécessite de chercher activement les cas d\\'échec, de comprendre les mécanismes de sélection, et de calculer les taux de base du succès.",
    "example": "Studying only successful entrepreneurs without considering the many who failed. Following advice from visible millionaires, not invisible bankrupts. Copying strategies of surviving companies.",
    "exampleFr": "Étudier uniquement les entrepreneurs à succès sans considérer ceux qui ont échoué. Suivre les conseils de millionnaires visibles, pas des faillis invisibles. Copier les stratégies des entreprises survivantes.",
    "icon": "zap"
  },
  {
    "id": 26,
    "name": "Projection Bias",
    "nameFr": "Biais de projection",
    "slug": "projection-bias",
    "summary": "Assuming others share your beliefs and values",
    "summaryFr": "Supposer que les autres partagent vos croyances et valeurs",
    "description": "Projection bias encompasses two related phenomena: assuming other people share our preferences, beliefs, and values (social projection), and assuming our future selves will have the same preferences as our current selves (intertemporal projection). Both stem from the difficulty of imagining perspectives different from our current one. Social projection leads product developers to build what they want rather than what customers need, negotiators to misjudge counterparts\\' priorities, and managers to assume employees are motivated by the same things they are. Intertemporal projection causes us to overestimate how much we\\'ll enjoy future purchases based on current desires (shopping hungry leads to buying too much food), underestimate how our preferences will change (career choices made at 20 may not fit at 40), and make commitments our future selves will regret. Research shows we struggle to imagine states different from our current one—when full, we can\\'t imagine being hungry. In organizations, projection bias contributes to failed products, ineffective incentives, and communication breakdowns. Counteracting it requires actively seeking input from diverse perspectives, conducting actual user research rather than imagining user needs, and building in flexibility for changing preferences.",
    "descriptionFr": "Le biais de projection englobe deux phénomènes liés : supposer que les autres partagent nos préférences, croyances et valeurs (projection sociale), et supposer que notre moi futur aura les mêmes préférences que notre moi actuel (projection intertemporelle). Les deux découlent de la difficulté d\\'imaginer des perspectives différentes de la nôtre actuelle. La projection sociale amène les développeurs de produits à construire ce qu\\'ils veulent plutôt que ce dont les clients ont besoin, les négociateurs à mal évaluer les priorités des contreparties, et les managers à supposer que les employés sont motivés par les mêmes choses qu\\'eux. La projection intertemporelle nous fait surestimer combien nous apprécierons les achats futurs basés sur les désirs actuels (faire les courses en ayant faim mène à acheter trop), sous-estimer comment nos préférences changeront. La recherche montre que nous luttons pour imaginer des états différents de notre état actuel. Contrer ce biais nécessite de chercher activement des perspectives diverses, de mener de vraies recherches utilisateur plutôt que d\\'imaginer les besoins des utilisateurs, et de prévoir de la flexibilité pour les préférences changeantes.",
    "example": "Designing a product based on what you want, not customer research. Shopping hungry and buying too much food. Assuming employees are motivated by what motivates you.",
    "exampleFr": "Concevoir un produit basé sur ce que vous voulez, pas sur la recherche client. Faire les courses en ayant faim et acheter trop. Supposer que les employés sont motivés par ce qui vous motive.",
    "icon": "shield"
  },
  {
    "id": 27,
    "name": "Contrast Effect",
    "nameFr": "Effet de contraste",
    "slug": "contrast-effect",
    "summary": "Judging things based on comparison to adjacent options",
    "summaryFr": "Juger les choses en fonction de la comparaison avec les options adjacentes",
    "description": "The contrast effect is a perceptual phenomenon where our evaluation of something is altered by comparison to something recently experienced. A room-temperature drink feels cold after holding ice, and warm after holding a hot cup. This effect extends from physical perception to judgments about people, products, and situations. In hiring, a mediocre candidate seems excellent after a series of weak ones, and an excellent candidate may seem merely average after an outstanding one. Real estate agents exploit this by showing overpriced or undesirable properties first to make the target property seem like a bargain. Salary negotiations are affected by the first number mentioned. The contrast effect is related to but distinct from anchoring—while anchoring involves a reference point for estimation, contrast affects qualitative perception. The effect means evaluations are never truly objective; they\\'re always relative to recent experiences. This creates problems when sequence affects judgment (interview order, presentation order). Mitigating the contrast effect requires evaluating options against absolute criteria rather than each other, randomizing sequences when possible, building in breaks between evaluations, and being aware that recent experiences color current perceptions.",
    "descriptionFr": "L\\'effet de contraste est un phénomène perceptuel où notre évaluation de quelque chose est altérée par comparaison à quelque chose récemment expérimenté. Une boisson à température ambiante semble froide après avoir tenu de la glace, et chaude après avoir tenu une tasse chaude. Cet effet s\\'étend de la perception physique aux jugements sur les personnes, produits et situations. En recrutement, un candidat médiocre semble excellent après une série de faibles, et un excellent candidat peut sembler simplement moyen après un exceptionnel. Les agents immobiliers exploitent cela en montrant d\\'abord des propriétés trop chères ou indésirables pour que la propriété cible semble une bonne affaire. Les négociations salariales sont affectées par le premier chiffre mentionné. L\\'effet de contraste est lié mais distinct de l\\'ancrage—alors que l\\'ancrage implique un point de référence pour l\\'estimation, le contraste affecte la perception qualitative. L\\'effet signifie que les évaluations ne sont jamais vraiment objectives ; elles sont toujours relatives aux expériences récentes. Atténuer l\\'effet de contraste nécessite d\\'évaluer les options par rapport à des critères absolus plutôt qu\\'entre elles et de randomiser les séquences quand c\\'est possible.",
    "example": "A mediocre candidate seeming excellent after interviewing several weak ones. A house seeming like a bargain after viewing overpriced ones. Food tasting bland after spicy dishes.",
    "exampleFr": "Un candidat médiocre semblant excellent après en avoir interviewé plusieurs faibles. Une maison semblant une bonne affaire après avoir vu des propriétés trop chères. La nourriture semblant fade après des plats épicés.",
    "icon": "users"
  },
  {
    "id": 28,
    "name": "Blind Spot Bias",
    "nameFr": "Biais de l\\'angle mort",
    "slug": "blind-spot-bias",
    "summary": "Recognizing biases in others but not in yourself",
    "summaryFr": "Reconnaître les biais chez les autres mais pas chez soi",
    "description": "Blind spot bias is the cognitive blind spot in recognizing our own cognitive biases. Research shows that people readily identify biases in others while rating themselves as less susceptible. This \"bias about biases\" is particularly pernicious because it undermines efforts at self-improvement: if you don\\'t believe you\\'re biased, you won\\'t try to correct for it. The asymmetry exists because we have direct access to our own thought processes (which feel logical and well-reasoned to us) but can only observe others\\' behavior (which may seem biased). We also motivate ourselves to see ourselves favorably. Ironically, learning about biases can increase blind spot bias—we may think our knowledge protects us while still falling victim to the same biases. Even intelligence doesn\\'t protect against blind spot bias; some research suggests more intelligent people may be even more susceptible because they\\'re better at rationalizing their biased conclusions. The antidote requires genuine intellectual humility, systematically seeking external perspectives, creating checklists and procedures that don\\'t rely on self-assessment, and assuming you\\'re at least as biased as those around you.",
    "descriptionFr": "Le biais de l\\'angle mort est l\\'angle mort cognitif dans la reconnaissance de nos propres biais cognitifs. La recherche montre que les gens identifient facilement les biais chez les autres tout en s\\'évaluant comme moins susceptibles. Ce \"biais sur les biais\" est particulièrement pernicieux car il mine les efforts d\\'amélioration personnelle : si vous ne croyez pas être biaisé, vous n\\'essaierez pas de corriger. L\\'asymétrie existe parce que nous avons un accès direct à nos propres processus de pensée (qui nous semblent logiques et bien raisonnés) mais ne pouvons observer que le comportement des autres (qui peut sembler biaisé). Nous nous motivons aussi à nous voir favorablement. Ironiquement, apprendre sur les biais peut augmenter le biais de l\\'angle mort—nous pouvons penser que notre connaissance nous protège tout en tombant victimes des mêmes biais. Même l\\'intelligence ne protège pas ; certaines recherches suggèrent que les personnes plus intelligentes peuvent être encore plus susceptibles parce qu\\'elles sont meilleures pour rationaliser leurs conclusions biaisées. L\\'antidote nécessite une véritable humilité intellectuelle, chercher systématiquement des perspectives externes, et supposer que vous êtes au moins aussi biaisé que ceux autour de vous.",
    "example": "Criticizing a colleague for favoritism while showing your own. Believing you\\'re objective while others are biased. Thinking learning about biases makes you immune to them.",
    "exampleFr": "Critiquer un collègue pour favoritisme tout en montrant le vôtre. Croire que vous êtes objectif alors que les autres sont biaisés. Penser qu\\'apprendre sur les biais vous immunise contre eux.",
    "icon": "trending-up"
  },
  {
    "id": 29,
    "name": "Hyperbolic Discounting",
    "nameFr": "Dévaluation hyperbolique",
    "slug": "hyperbolic-discounting",
    "summary": "Preferring immediate rewards over larger future gains",
    "summaryFr": "Préférer les récompenses immédiates aux gains futurs plus importants",
    "description": "Hyperbolic discounting is a time-inconsistent preference pattern where we disproportionately value immediate rewards over future ones. Unlike economically rational exponential discounting (where value decreases smoothly over time), hyperbolic discounting creates a sharp drop in value for anything not immediate. We prefer $100 today over $110 tomorrow, but we\\'re indifferent between $100 in 30 days and $110 in 31 days—even though both choices involve the same one-day wait. This creates the phenomenon of preference reversal: we make commitments to our future selves that our present selves then violate when the time comes. It explains procrastination (immediate comfort beats future completion), undersaving (present consumption beats future security), addiction (immediate pleasure beats long-term health), and impulse buying (immediate satisfaction beats financial goals). Our future selves are strangers to us—brain imaging shows we process future-self benefits more like we process benefits to other people. Strategies to combat hyperbolic discounting include commitment devices (binding future choices), automation (removing moment-of-decision temptation), mental time travel (vividly imagining future states), and reducing the friction of future-oriented choices while increasing the friction of short-term temptations.",
    "descriptionFr": "La dévaluation hyperbolique est un schéma de préférence temporellement incohérent où nous valorisons de manière disproportionnée les récompenses immédiates par rapport aux futures. Contrairement à l\\'actualisation exponentielle économiquement rationnelle (où la valeur diminue régulièrement dans le temps), la dévaluation hyperbolique crée une chute brutale de la valeur pour tout ce qui n\\'est pas immédiat. Nous préférons 100€ aujourd\\'hui à 110€ demain, mais sommes indifférents entre 100€ dans 30 jours et 110€ dans 31 jours—même si les deux choix impliquent la même attente d\\'un jour. Cela crée le phénomène d\\'inversion de préférence : nous prenons des engagements envers notre moi futur que notre moi présent viole quand le moment vient. Cela explique la procrastination (le confort immédiat bat l\\'achèvement futur), la sous-épargne (la consommation présente bat la sécurité future), l\\'addiction (le plaisir immédiat bat la santé à long terme), et les achats impulsifs. Les stratégies pour combattre la dévaluation hyperbolique incluent les dispositifs d\\'engagement (lier les choix futurs), l\\'automatisation (supprimer la tentation au moment de la décision), le voyage mental dans le temps (imaginer vivement les états futurs), et réduire la friction des choix orientés vers le futur.",
    "example": "Accepting a quick cash bonus instead of stock options worth more later. Procrastinating on important tasks for immediate comfort. Spending now instead of saving for retirement.",
    "exampleFr": "Accepter un bonus en espèces rapide au lieu d\\'options d\\'actions valant plus tard. Procrastiner sur des tâches importantes pour le confort immédiat. Dépenser maintenant au lieu d\\'épargner pour la retraite.",
    "icon": "lightbulb"
  },
  {
    "id": 30,
    "name": "Choice Overload",
    "nameFr": "Surcharge de choix",
    "slug": "choice-overload",
    "summary": "Being paralyzed by too many options",
    "summaryFr": "Être paralysé par trop d\\'options",
    "description": "Choice overload (also called the \"paradox of choice\") describes how having too many options can be debilitating rather than liberating. In Sheena Iyengar\\'s famous jam study, shoppers were more likely to buy jam when presented with 6 options versus 24—despite more interest in the larger display. Too many choices increase cognitive load, create fear of missing out on the \"best\" option, raise expectations, and generate more opportunity for post-decision regret. In consumer contexts, it leads to decision paralysis, lower satisfaction with chosen options, and avoidance of choice altogether. In organizations, excessive options in processes or policies can cause inaction. The effect is moderated by expertise (experts can handle more options), preference clarity (knowing what you want reduces overload), and category complexity. Strategies to combat choice overload include limiting the number of options presented, organizing choices into categories, establishing clear decision criteria beforehand, using satisficing (choosing \"good enough\") rather than maximizing, accepting that no choice is perfect, and setting time limits on decision processes to prevent endless comparison.",
    "descriptionFr": "La surcharge de choix (aussi appelée \"paradoxe du choix\") décrit comment avoir trop d\\'options peut être débilitant plutôt que libérateur. Dans la célèbre étude sur les confitures de Sheena Iyengar, les acheteurs étaient plus susceptibles d\\'acheter de la confiture avec 6 options versus 24—malgré plus d\\'intérêt pour le plus grand présentoir. Trop de choix augmentent la charge cognitive, créent la peur de rater la \"meilleure\" option, élèvent les attentes, et génèrent plus d\\'opportunités de regret post-décision. Dans les contextes de consommation, cela mène à la paralysie décisionnelle, une satisfaction plus basse avec les options choisies, et l\\'évitement du choix. Dans les organisations, des options excessives dans les processus ou politiques peuvent causer l\\'inaction. L\\'effet est modéré par l\\'expertise (les experts peuvent gérer plus d\\'options), la clarté des préférences (savoir ce que vous voulez réduit la surcharge), et la complexité de la catégorie. Les stratégies pour combattre la surcharge incluent limiter le nombre d\\'options présentées, organiser les choix en catégories, établir des critères de décision clairs au préalable, utiliser la \"satisficing\" (choisir \"assez bien\") plutôt que maximiser, et fixer des limites de temps sur les processus de décision.",
    "example": "Spending weeks comparing dozens of products and buying nothing. Feeling less satisfied after choosing from many options. Avoiding decisions because there are too many choices.",
    "exampleFr": "Passer des semaines à comparer des dizaines de produits et ne rien acheter. Se sentir moins satisfait après avoir choisi parmi de nombreuses options. Éviter les décisions parce qu\\'il y a trop de choix.",
    "icon": "compass"
  },
  {
    "id": 31,
    "name": "Spotlight Effect",
    "nameFr": "Effet de projecteur",
    "slug": "spotlight-effect",
    "summary": "Overestimating how much others notice you",
    "summaryFr": "Surestimer à quel point les autres vous remarquent",
    "description": "The spotlight effect is the tendency to overestimate how much others notice about us—our appearance, behaviors, and mistakes. Research by Thomas Gilovich showed that people who wore embarrassing T-shirts vastly overestimated how many others would notice or remember them. This occurs because we are the center of our own world: everything we do feels significant to us, and we project that significance onto others\\' perceptions. The spotlight effect is related to egocentrism—not selfishness, but the cognitive difficulty of getting outside our own perspective. Others are occupied with their own concerns and pay far less attention to us than we imagine. The effect has consequences for social anxiety (we fear judgment that often isn\\'t happening), risk-taking (we avoid actions that would go unnoticed anyway), and authenticity (we censor ourselves unnecessarily). In presentations and meetings, minor stumbles feel catastrophic to us but are often not noticed or quickly forgotten by audiences. Understanding the spotlight effect can reduce social anxiety, encourage calculated risk-taking, and promote more authentic behavior by recognizing that others\\' attention is a limited resource rarely focused on us.",
    "descriptionFr": "L\\'effet de projecteur est la tendance à surestimer combien les autres remarquent nous concernant—notre apparence, comportements et erreurs. La recherche de Thomas Gilovich a montré que les gens portant des T-shirts embarrassants surestimaient grandement combien d\\'autres le remarqueraient ou s\\'en souviendraient. Cela se produit parce que nous sommes le centre de notre propre monde : tout ce que nous faisons nous semble significatif, et nous projetons cette signification sur les perceptions des autres. L\\'effet de projecteur est lié à l\\'égocentrisme—pas l\\'égoïsme, mais la difficulté cognitive de sortir de notre propre perspective. Les autres sont occupés par leurs propres préoccupations et nous prêtent bien moins d\\'attention que nous l\\'imaginons. L\\'effet a des conséquences pour l\\'anxiété sociale (nous craignons un jugement qui souvent n\\'arrive pas), la prise de risque (nous évitons des actions qui passeraient inaperçues), et l\\'authenticité (nous nous censurons inutilement). Dans les présentations et réunions, les petits trébuchements nous semblent catastrophiques mais sont souvent non remarqués ou rapidement oubliés par les audiences. Comprendre l\\'effet de projecteur peut réduire l\\'anxiété sociale et encourager une prise de risque calculée.",
    "example": "Being embarrassed about a small stain when no one noticed. Obsessing over a mistake in a presentation that the audience forgot. Avoiding speaking up for fear of looking foolish.",
    "exampleFr": "Être gêné par une petite tache que personne n\\'a remarquée. Être obsédé par une erreur de présentation que l\\'audience a oubliée. Éviter de parler par peur de paraître stupide.",
    "icon": "alert-triangle"
  },
  {
    "id": 32,
    "name": "In-group Bias",
    "nameFr": "Biais de groupe",
    "slug": "in-group-bias",
    "summary": "Favoring members of your own group",
    "summaryFr": "Favoriser les membres de votre propre groupe",
    "description": "In-group bias (or in-group favoritism) is the tendency to favor members of one\\'s own group over outsiders. Henri Tajfel\\'s \"minimal group\" experiments showed that even arbitrary groupings (like preferring one abstract painter over another) triggered preferential treatment of in-group members. The bias operates unconsciously and automatically. We allocate more resources, extend more trust, give more charitable interpretations, and provide more positive evaluations to those we perceive as \"us.\" Evolutionarily, this made sense: cooperating with your tribe increased survival. But in modern contexts, it creates problems. In hiring, we favor candidates who share our background. In performance reviews, we rate in-group members higher. In conflicts, we assume bad intent from out-groups while granting benefit of the doubt to in-groups. The bias perpetuates homogeneity and inequality. It\\'s often invisible to those displaying it—we don\\'t see ourselves as biased; we just \"click better\" with certain people. Counteracting in-group bias requires awareness of group boundaries, structured decision-making processes that reduce discretion, diverse decision-making bodies, and explicit evaluation criteria applied consistently.",
    "descriptionFr": "Le biais de groupe (ou favoritisme intra-groupe) est la tendance à favoriser les membres de son propre groupe par rapport aux étrangers. Les expériences de \"groupe minimal\" d\\'Henri Tajfel ont montré que même des groupements arbitraires (comme préférer un peintre abstrait à un autre) déclenchaient un traitement préférentiel des membres du groupe. Le biais opère inconsciemment et automatiquement. Nous allouons plus de ressources, accordons plus de confiance, donnons des interprétations plus charitables, et fournissons des évaluations plus positives à ceux que nous percevons comme \"nous.\" Évolutivement, cela avait du sens : coopérer avec votre tribu augmentait la survie. Mais dans les contextes modernes, cela crée des problèmes. En recrutement, nous favorisons les candidats qui partagent notre parcours. Dans les évaluations de performance, nous notons plus haut les membres du groupe. Dans les conflits, nous supposons de mauvaises intentions des groupes extérieurs tout en accordant le bénéfice du doute aux groupes internes. Contrer le biais de groupe nécessite une conscience des frontières de groupe, des processus de décision structurés qui réduisent la discrétion, et des critères d\\'évaluation explicites appliqués de manière cohérente.",
    "example": "A manager giving better projects to people from their alma mater. Trusting information from someone who shares your nationality more. Rating in-group members higher in reviews.",
    "exampleFr": "Un manager donnant de meilleurs projets aux gens de son alma mater. Faire plus confiance aux informations de quelqu\\'un partageant votre nationalité. Noter plus haut les membres du groupe dans les évaluations.",
    "icon": "heart"
  },
  {
    "id": 33,
    "name": "IKEA Effect",
    "nameFr": "Effet IKEA",
    "slug": "ikea-effect",
    "summary": "Overvaluing things you helped create",
    "summaryFr": "Surévaluer les choses que vous avez aidé à créer",
    "description": "The IKEA effect, named after the furniture company whose products require self-assembly, describes the tendency to place disproportionate value on things we helped create, regardless of their objective quality. Research by Michael Norton, Daniel Mochon, and Dan Ariely showed that people valued self-assembled IKEA furniture more highly than identical pre-assembled items—and also overestimated how much others would value it. The effect requires successful completion: a half-built piece holds less appeal. Psychologically, the effect stems from feelings of competence, the desire for positive self-concept, and the effort invested creating links to value. Labor becomes love. In business, the IKEA effect creates dangerous blind spots. Leaders become attached to strategies they developed, engineers to code they wrote, designers to solutions they created—defending them past the point of reason. It contributes to \"not invented here\" syndrome, where external ideas are rejected in favor of inferior internal ones. Mitigating the effect requires awareness that our creations feel more valuable than they are, seeking objective feedback, establishing evaluation criteria before creation, and creating decision processes that separate creators from evaluators.",
    "descriptionFr": "L\\'effet IKEA, nommé d\\'après l\\'entreprise de meubles dont les produits nécessitent un auto-assemblage, décrit la tendance à accorder une valeur disproportionnée aux choses que nous avons aidé à créer, indépendamment de leur qualité objective. La recherche de Michael Norton, Daniel Mochon et Dan Ariely a montré que les gens valorisaient les meubles IKEA auto-assemblés plus que des articles pré-assemblés identiques—et surestimaient aussi combien les autres les valoriseraient. L\\'effet nécessite un achèvement réussi : une pièce à moitié construite attire moins. Psychologiquement, l\\'effet découle des sentiments de compétence, du désir d\\'un concept de soi positif, et de l\\'effort investi créant des liens avec la valeur. Le travail devient amour. En affaires, l\\'effet IKEA crée des angles morts dangereux. Les leaders s\\'attachent aux stratégies qu\\'ils ont développées, les ingénieurs au code qu\\'ils ont écrit, les designers aux solutions qu\\'ils ont créées—les défendant au-delà de la raison. Atténuer l\\'effet nécessite une conscience que nos créations semblent plus précieuses qu\\'elles ne sont, chercher des retours objectifs, établir des critères d\\'évaluation avant la création, et créer des processus de décision qui séparent créateurs et évaluateurs.",
    "example": "Being attached to a strategy you developed even when data shows failure. Defending your code against valid criticism. Preferring in-house solutions over better external ones.",
    "exampleFr": "Être attaché à une stratégie que vous avez développée même si les données montrent un échec. Défendre votre code contre des critiques valides. Préférer les solutions internes à de meilleures externes.",
    "icon": "bookmark"
  },
  {
    "id": 34,
    "name": "Zero-risk Bias",
    "nameFr": "Biais du risque zéro",
    "slug": "zero-risk-bias",
    "summary": "Preferring to eliminate one risk completely over reducing overall risk",
    "summaryFr": "Préférer éliminer complètement un risque plutôt que réduire le risque global",
    "description": "Zero-risk bias is the preference for completely eliminating one risk rather than achieving a greater overall reduction in risk. Given a choice between reducing a 5% risk to 0% or reducing a 50% risk to 25%, people often prefer the first option—even though the second reduces more expected harm. The complete elimination of a risk feels more psychologically satisfying than larger but partial reductions. Zero-risk bias relates to our difficulty processing probabilistic information and our desire for certainty. A \"zero\" feels categorical and final, while percentages feel uncertain and ongoing. It\\'s exploited in marketing (\"100% satisfaction guaranteed\") and policy debates (demands for \"zero tolerance\" policies). In organizational decision-making, zero-risk bias leads to misallocated resources—spending heavily to eliminate minor risks while larger risks go under-addressed. It can create a false sense of security: eliminating one small risk while ignoring the overall risk landscape. Rational risk management requires thinking in terms of expected value and total risk reduction rather than the appeal of \"zero.\" This means accepting that some residual risk is often optimal, that resources are finite, and that the marginal cost of complete elimination often exceeds its marginal benefit.",
    "descriptionFr": "Le biais du risque zéro est la préférence pour éliminer complètement un risque plutôt que d\\'atteindre une plus grande réduction globale du risque. Devant le choix entre réduire un risque de 5% à 0% ou réduire un risque de 50% à 25%, les gens préfèrent souvent la première option—même si la seconde réduit plus de dommages attendus. L\\'élimination complète d\\'un risque semble plus psychologiquement satisfaisante que des réductions plus grandes mais partielles. Le biais du risque zéro est lié à notre difficulté à traiter l\\'information probabiliste et notre désir de certitude. Un \"zéro\" semble catégorique et final, tandis que les pourcentages semblent incertains et continus. Il est exploité en marketing (\"satisfaction 100% garantie\") et dans les débats politiques (demandes de politiques de \"tolérance zéro\"). Dans la prise de décision organisationnelle, le biais du risque zéro mène à une mauvaise allocation des ressources—dépenser lourdement pour éliminer des risques mineurs tandis que des risques plus grands sont sous-traités. La gestion rationnelle du risque nécessite de penser en termes de valeur attendue et de réduction totale du risque plutôt que l\\'attrait du \"zéro.\"",
    "example": "Spending all your security budget on one perfect system instead of improving overall security. Demanding zero defects when reducing defects by 90% is more practical.",
    "exampleFr": "Dépenser tout votre budget sécurité sur un système parfait au lieu d\\'améliorer la sécurité globale. Exiger zéro défaut quand réduire les défauts de 90% est plus pratique.",
    "icon": "filter"
  },
  {
    "id": 35,
    "name": "Hot-cold Empathy Gap",
    "nameFr": "Fossé empathique chaud-froid",
    "slug": "hot-cold-empathy-gap",
    "summary": "Underestimating how emotions affect decisions",
    "summaryFr": "Sous-estimer comment les émotions affectent les décisions",
    "description": "The hot-cold empathy gap, researched extensively by George Loewenstein, describes our inability to accurately predict how we\\'ll feel and behave in different emotional states. When \"cold\" (calm, satiated, comfortable), we underestimate the influence of \"hot\" states (angry, hungry, aroused, in pain) on our decisions. When hot, we underestimate how differently we\\'ll feel when cold. This creates systematic prediction errors. Satiated, we underestimate how much we\\'ll eat when hungry (and overbuy groceries). Calm, we underestimate how anger will affect our negotiations. Comfortable, we underestimate how pain will affect our judgment. The gap works in both directions: while experiencing strong emotions, we fail to recognize how temporary they are and make decisions we\\'ll later regret. The empathy gap also affects our understanding of others: we struggle to empathize with someone in a different emotional state. Drug addicts in withdrawal are judged harshly by those who\\'ve never experienced cravings. Strategies to bridge the gap include making important decisions in neutral states, building in cooling-off periods before consequential choices, using precommitment devices, and actively imagining (through visualization or even mild exposure) how the target emotional state might affect judgment.",
    "descriptionFr": "Le fossé empathique chaud-froid, étudié en profondeur par George Loewenstein, décrit notre incapacité à prédire avec précision comment nous nous sentirons et nous comporterons dans différents états émotionnels. Quand nous sommes \"froids\" (calmes, rassasiés, confortables), nous sous-estimons l\\'influence des états \"chauds\" (en colère, affamés, excités, souffrants) sur nos décisions. Quand nous sommes chauds, nous sous-estimons combien nous nous sentirons différemment quand nous serons froids. Cela crée des erreurs de prédiction systématiques. Rassasiés, nous sous-estimons combien nous mangerons quand nous aurons faim. Calmes, nous sous-estimons comment la colère affectera nos négociations. Confortables, nous sous-estimons comment la douleur affectera notre jugement. Le fossé fonctionne dans les deux sens : en expérimentant des émotions fortes, nous ne reconnaissons pas combien elles sont temporaires et prenons des décisions que nous regretterons plus tard. Le fossé d\\'empathie affecte aussi notre compréhension des autres : nous luttons pour sympathiser avec quelqu\\'un dans un état émotionnel différent. Les stratégies pour combler le fossé incluent prendre des décisions importantes dans des états neutres et utiliser des dispositifs de préengagement.",
    "example": "Planning to stay calm during a negotiation but becoming defensive. Underestimating hunger and overbuying groceries. Promising patience when calm but snapping under stress.",
    "exampleFr": "Prévoir de rester calme pendant une négociation mais devenir défensif. Sous-estimer la faim et trop acheter. Promettre patience quand calme mais craquer sous le stress.",
    "icon": "sun"
  },
  {
    "id": 36,
    "name": "Decoy Effect",
    "nameFr": "Effet leurre",
    "slug": "decoy-effect",
    "summary": "Preferences change when a third option is added",
    "summaryFr": "Les préférences changent quand une troisième option est ajoutée",
    "description": "The decoy effect (also called asymmetric dominance) occurs when adding a third option changes preferences between the original two. The decoy is designed to be inferior to one option but not clearly comparable to the other. For example, if consumers are choosing between a small $3 popcorn and large $7 one, adding a medium at $6.50 makes the large seem like a great deal. The decoy (medium) is clearly worse than the large but not clearly comparable to the small—it makes the large \"dominant\" and increases its selection. The effect violates the principle of \"independence of irrelevant alternatives\" in rational choice theory: preferences between A and B shouldn\\'t change because C is added. But humans aren\\'t rational. We evaluate options relatively, and decoys manipulate the comparison set. Marketers use decoys in pricing strategies, subscription tiers, and product lineups. Real estate agents show an inferior property to make the target property more appealing. In negotiations, an extreme initial offer can make subsequent offers seem reasonable by comparison. Awareness of the decoy effect helps in recognizing when options are structured to manipulate choice, and in evaluating each option on its absolute merits rather than relative to cleverly positioned alternatives.",
    "descriptionFr": "L\\'effet leurre (aussi appelé dominance asymétrique) se produit lorsque l\\'ajout d\\'une troisième option change les préférences entre les deux originales. Le leurre est conçu pour être inférieur à une option mais pas clairement comparable à l\\'autre. Par exemple, si les consommateurs choisissent entre un petit popcorn à 3€ et un grand à 7€, ajouter un moyen à 6,50€ fait paraître le grand comme une bonne affaire. Le leurre (moyen) est clairement pire que le grand mais pas clairement comparable au petit—il rend le grand \"dominant\" et augmente sa sélection. L\\'effet viole le principe d\\'\"indépendance des alternatives non pertinentes\" dans la théorie du choix rationnel : les préférences entre A et B ne devraient pas changer parce que C est ajouté. Mais les humains ne sont pas rationnels. Nous évaluons les options relativement, et les leurres manipulent l\\'ensemble de comparaison. Les marketeurs utilisent les leurres dans les stratégies de prix, les niveaux d\\'abonnement et les gammes de produits. Les agents immobiliers montrent une propriété inférieure pour rendre la propriété cible plus attrayante. La conscience de l\\'effet leurre aide à reconnaître quand les options sont structurées pour manipuler le choix et à évaluer chaque option sur ses mérites absolus.",
    "example": "A medium popcorn at $6.50 making the $7 large seem like a great deal. An inferior candidate making another candidate look stronger. A subscription tier making the premium tier seem worthwhile.",
    "exampleFr": "Un popcorn moyen à 6,50€ faisant paraître le grand à 7€ comme une bonne affaire. Un candidat inférieur faisant paraître un autre candidat plus fort. Un niveau d\\'abonnement faisant paraître le niveau premium intéressant.",
    "icon": "moon"
  },
  {
    "id": 37,
    "name": "Just-world Hypothesis",
    "nameFr": "Hypothèse du monde juste",
    "slug": "just-world-hypothesis",
    "summary": "Believing people get what they deserve",
    "summaryFr": "Croire que les gens obtiennent ce qu\\'ils méritent",
    "description": "The just-world hypothesis, researched by Melvin Lerner, is the belief that the world is fundamentally fair—that people get what they deserve and deserve what they get. Good things happen to good people; bad things happen to bad people. While this belief provides psychological comfort (if the world is just, we can control our outcomes through our behavior), it leads to problematic conclusions. It causes victim-blaming: if bad things happen to people, they must have done something to deserve it. It leads to assuming successful people are morally superior and unsuccessful people are morally inferior. It underestimates the role of luck, privilege, and systemic factors in outcomes. In organizations, just-world beliefs can lead to blaming laid-off workers for their job loss, assuming high performers are more ethical, and failing to address systemic barriers. Research shows people go to remarkable lengths to maintain just-world beliefs—reinterpreting events, derogating victims, or rationalizing injustice. The antidote is recognizing that correlation between behavior and outcomes exists but is imperfect, that luck plays a substantial role in life outcomes, and that structural factors create unequal playing fields that individual merit cannot fully overcome.",
    "descriptionFr": "L\\'hypothèse du monde juste, étudiée par Melvin Lerner, est la croyance que le monde est fondamentalement juste—que les gens obtiennent ce qu\\'ils méritent et méritent ce qu\\'ils obtiennent. Les bonnes choses arrivent aux bonnes personnes ; les mauvaises aux mauvaises. Bien que cette croyance apporte un réconfort psychologique (si le monde est juste, nous pouvons contrôler nos résultats par notre comportement), elle mène à des conclusions problématiques. Elle cause le blâme des victimes : si de mauvaises choses arrivent aux gens, ils doivent avoir fait quelque chose pour le mériter. Elle mène à supposer que les gens qui réussissent sont moralement supérieurs et ceux qui ne réussissent pas sont moralement inférieurs. Elle sous-estime le rôle de la chance, du privilège et des facteurs systémiques dans les résultats. Dans les organisations, les croyances du monde juste peuvent mener à blâmer les travailleurs licenciés pour leur perte d\\'emploi, supposer que les hauts performeurs sont plus éthiques, et échouer à traiter les barrières systémiques. L\\'antidote est de reconnaître que la corrélation entre comportement et résultats existe mais est imparfaite, que la chance joue un rôle substantiel dans les résultats de vie, et que les facteurs structurels créent des terrains de jeu inégaux.",
    "example": "Assuming someone who got laid off must have been a poor performer. Believing the wealthy are morally superior. Blaming victims of misfortune for their situation.",
    "exampleFr": "Supposer que quelqu\\'un qui a été licencié devait être un mauvais performeur. Croire que les riches sont moralement supérieurs. Blâmer les victimes de malheur pour leur situation.",
    "icon": "star"
  },
  {
    "id": 38,
    "name": "Base Rate Neglect",
    "nameFr": "Négligence du taux de base",
    "slug": "base-rate-neglect",
    "summary": "Ignoring general statistics in favor of specific information",
    "summaryFr": "Ignorer les statistiques générales en faveur d\\'informations spécifiques",
    "description": "Base rate neglect (or base rate fallacy) is the tendency to ignore general statistical information (base rates) in favor of specific case information, even when the base rate is more predictive. In Kahneman and Tversky\\'s classic \"lawyer-engineer problem,\" people given a personality description ignored whether the person was drawn from a pool of 70% lawyers or 70% engineers—the description dominated their judgment. We are drawn to stories, not statistics. This creates systematic errors. When evaluating a job candidate\\'s impressive interview, we neglect that most impressive interviews don\\'t predict job performance. When excited about a startup\\'s compelling pitch, we neglect that 90% of startups fail. Medical diagnosis is particularly vulnerable: a positive test result feels definitive, but interpretation requires knowing the base rate of the disease and false positive rate of the test. Base rate neglect leads to overconfidence in individual predictions and underuse of statistical regularities. Correcting it requires consciously asking \"what\\'s the base rate?\" before being swayed by individual-case information, using Bayesian reasoning that combines base rates with case-specific evidence, and creating decision processes that force consideration of relevant statistics.",
    "descriptionFr": "La négligence du taux de base (ou erreur du taux de base) est la tendance à ignorer les informations statistiques générales (taux de base) en faveur d\\'informations de cas spécifiques, même quand le taux de base est plus prédictif. Dans le classique \"problème avocat-ingénieur\" de Kahneman et Tversky, les personnes recevant une description de personnalité ignoraient si la personne était tirée d\\'un groupe de 70% d\\'avocats ou 70% d\\'ingénieurs—la description dominait leur jugement. Nous sommes attirés par les histoires, pas les statistiques. Cela crée des erreurs systématiques. En évaluant l\\'interview impressionnante d\\'un candidat, nous négligeons que la plupart des interviews impressionnantes ne prédisent pas la performance au travail. Excités par le pitch convaincant d\\'une startup, nous négligeons que 90% des startups échouent. Le diagnostic médical est particulièrement vulnérable : un résultat de test positif semble définitif, mais l\\'interprétation nécessite de connaître le taux de base de la maladie et le taux de faux positifs du test. Corriger cela nécessite de demander consciemment \"quel est le taux de base ?\" avant d\\'être influencé par les informations de cas individuels et d\\'utiliser un raisonnement bayésien qui combine les taux de base avec les preuves spécifiques au cas.",
    "example": "Investing in a startup because the founder is charismatic, ignoring that 90% fail. Believing a positive medical test is definitive without considering false positive rates.",
    "exampleFr": "Investir dans une startup parce que le fondateur est charismatique, ignorant que 90% échouent. Croire qu\\'un test médical positif est définitif sans considérer les taux de faux positifs.",
    "icon": "coffee"
  },
  {
    "id": 39,
    "name": "Illusion of Control",
    "nameFr": "Illusion de contrôle",
    "slug": "illusion-of-control",
    "summary": "Believing you can influence random or uncontrollable events",
    "summaryFr": "Croire que vous pouvez influencer des événements aléatoires ou incontrôlables",
    "description": "The illusion of control, first described by Ellen Langer, is the tendency to believe we have more influence over outcomes than we actually do, especially in situations governed by chance or beyond our control. Langer\\'s research showed that people would pay more for lottery tickets they chose themselves versus randomly assigned ones—even though both have identical odds. The illusion is strengthened by personal involvement, familiarity with the situation, apparent skill elements, and early positive outcomes. In gambling, players develop rituals and strategies for games of pure chance. In investing, traders believe they can consistently beat the market despite evidence that even experts rarely do. In business, leaders overestimate how much success is due to their decisions versus market conditions or luck. The illusion has adaptive elements—it can increase motivation and persistence—but also significant downsides. It leads to excessive risk-taking, inadequate contingency planning, failure to diversify, and attribution of success to skill (reinforcing overconfidence) while blaming failure on bad luck. Correcting the illusion requires distinguishing between controllable and uncontrollable factors, studying base rates of success in domains, conducting pre-mortems to identify factors beyond control, and maintaining humility about the role of luck.",
    "descriptionFr": "L\\'illusion de contrôle, décrite pour la première fois par Ellen Langer, est la tendance à croire que nous avons plus d\\'influence sur les résultats que nous n\\'en avons réellement, surtout dans les situations gouvernées par le hasard ou hors de notre contrôle. La recherche de Langer a montré que les gens paieraient plus pour des billets de loterie qu\\'ils ont choisis eux-mêmes versus attribués au hasard—même si les deux ont des chances identiques. L\\'illusion est renforcée par l\\'implication personnelle, la familiarité avec la situation, des éléments apparents de compétence, et des résultats positifs précoces. Dans les jeux de hasard, les joueurs développent des rituels et stratégies pour des jeux de pur hasard. En investissement, les traders croient pouvoir constamment battre le marché malgré les preuves que même les experts y parviennent rarement. En affaires, les dirigeants surestiment combien le succès est dû à leurs décisions versus les conditions du marché ou la chance. L\\'illusion mène à une prise de risque excessive, une planification de contingence inadéquate, un échec à diversifier, et l\\'attribution du succès à la compétence (renforçant la surconfiance) tout en blâmant l\\'échec sur la malchance. Corriger l\\'illusion nécessite de distinguer entre facteurs contrôlables et incontrôlables et de maintenir l\\'humilité sur le rôle de la chance.",
    "example": "Believing your stock-picking skills can consistently beat the market. Developing rituals for games of pure chance. Attributing business success entirely to strategy, ignoring luck.",
    "exampleFr": "Croire que vos compétences de sélection d\\'actions peuvent battre le marché. Développer des rituels pour des jeux de pur hasard. Attribuer le succès business entièrement à la stratégie, ignorant la chance.",
    "icon": "key"
  },
  {
    "id": 40,
    "name": "Normalcy Bias",
    "nameFr": "Biais de normalité",
    "slug": "normalcy-bias",
    "summary": "Underestimating the possibility of disaster",
    "summaryFr": "Sous-estimer la possibilité d\\'une catastrophe",
    "description": "Normalcy bias causes people to underestimate both the likelihood and potential impact of disasters or dramatic changes. When faced with warning signs of impending crisis, people assume things will continue functioning as they always have. Studies of disaster response show that many people simply freeze or go about their routines when evacuations are ordered—they can\\'t process that something truly abnormal is happening. The bias developed because most of the time, abnormal signals are false alarms. Our brains evolved to filter out noise and focus on routine. But this creates dangerous blind spots when genuine threats emerge. Normalcy bias explains why people stay in deteriorating relationships, failing companies, or dangerous situations far too long. It explains why industries are disrupted by technologies they could have seen coming but dismissed as \"not how things work in our business.\" In organizations, normalcy bias leads to ignoring early warning signs, dismissing competitive threats, and failing to prepare for low-probability high-impact events. Overcoming it requires actively seeking disconfirming information, running scenario planning exercises for \"unthinkable\" situations, studying historical disruptions, and creating response plans before they\\'re needed.",
    "descriptionFr": "Le biais de normalité amène les gens à sous-estimer à la fois la probabilité et l\\'impact potentiel des catastrophes ou changements dramatiques. Confrontés aux signes d\\'alerte d\\'une crise imminente, les gens supposent que les choses continueront à fonctionner comme elles l\\'ont toujours fait. Les études de réponse aux catastrophes montrent que beaucoup de gens se figent simplement ou poursuivent leurs routines quand des évacuations sont ordonnées—ils ne peuvent pas traiter que quelque chose de vraiment anormal se passe. Le biais s\\'est développé parce que la plupart du temps, les signaux anormaux sont des fausses alarmes. Nos cerveaux ont évolué pour filtrer le bruit et se concentrer sur la routine. Mais cela crée des angles morts dangereux quand des menaces genuines émergent. Le biais de normalité explique pourquoi les gens restent dans des relations détériorantes, des entreprises en échec, ou des situations dangereuses bien trop longtemps. Il explique pourquoi les industries sont perturbées par des technologies qu\\'elles auraient pu voir venir mais qu\\'elles ont rejetées. Dans les organisations, le biais de normalité mène à ignorer les signes d\\'alerte précoces, rejeter les menaces concurrentielles, et échouer à se préparer pour des événements à faible probabilité mais fort impact. Le surmonter nécessite de chercher activement l\\'information contradictoire et d\\'exécuter des exercices de planification de scénarios pour des situations \"impensables.\"",
    "example": "Ignoring warning signs of market disruption because \"our industry has always been stable.\" Continuing routine activities during a disaster. Dismissing early signals of a pandemic.",
    "exampleFr": "Ignorer les signes d\\'alerte de perturbation du marché parce que \"notre industrie a toujours été stable.\" Continuer les activités routinières pendant une catastrophe. Rejeter les signaux précoces d\\'une pandémie.",
    "icon": "brain"
  },
  {
    "id": 41,
    "name": "Naive Realism",
    "nameFr": "Réalisme naïf",
    "slug": "naive-realism",
    "summary": "Believing your perception of reality is the objective truth",
    "summaryFr": "Croire que votre perception de la réalité est la vérité objective",
    "description": "Naive realism, studied by social psychologist Lee Ross, is the conviction that we perceive the world objectively, without bias—that our views reflect reality as it truly is. It comprises three assumptions: I see reality objectively; reasonable people will agree with me once they see the facts; those who disagree are either uninformed, irrational, or biased. This creates a framework where disagreement becomes evidence of others\\' deficiencies rather than legitimate alternative perspectives. Naive realism is particularly damaging in conflicts, where each side believes they see the situation clearly and the other side is distorted by bias or bad faith. It undermines negotiation and compromise: if I\\'m objectively right, why should I move toward an objectively wrong position? In organizations, it leads to dismissing valid feedback, assuming dissent reflects ignorance rather than different information or values, and escalating conflicts. The antidote is cultivating epistemic humility—recognizing that our perceptions are constructions influenced by our experiences, values, and cognitive processes, not direct windows to reality. Techniques include actively seeking to understand how situations look from others\\' perspectives, asking \"what might I be missing?\" and assuming people who disagree may have good reasons.",
    "descriptionFr": "Le réalisme naïf, étudié par le psychologue social Lee Ross, est la conviction que nous percevons le monde objectivement, sans biais—que nos vues reflètent la réalité telle qu\\'elle est vraiment. Il comprend trois suppositions : je vois la réalité objectivement ; les personnes raisonnables seront d\\'accord avec moi une fois qu\\'elles verront les faits ; ceux qui ne sont pas d\\'accord sont soit mal informés, irrationnels, ou biaisés. Cela crée un cadre où le désaccord devient une preuve des déficiences des autres plutôt que des perspectives alternatives légitimes. Le réalisme naïf est particulièrement dommageable dans les conflits, où chaque partie croit voir la situation clairement et l\\'autre côté est déformé par le biais ou la mauvaise foi. Il mine la négociation et le compromis : si j\\'ai objectivement raison, pourquoi devrais-je aller vers une position objectivement fausse ? Dans les organisations, il mène à rejeter les retours valides, supposer que la dissidence reflète l\\'ignorance plutôt que des informations ou valeurs différentes, et escalader les conflits. L\\'antidote est de cultiver l\\'humilité épistémique—reconnaître que nos perceptions sont des constructions influencées par nos expériences, valeurs et processus cognitifs, pas des fenêtres directes sur la réalité.",
    "example": "Dismissing a colleague\\'s concerns as them \"not understanding.\" Believing those who disagree must be biased. Assuming your interpretation of events is the only valid one.",
    "exampleFr": "Rejeter les préoccupations d\\'un collègue parce qu\\'il \"ne comprend pas.\" Croire que ceux qui ne sont pas d\\'accord doivent être biaisés. Supposer que votre interprétation des événements est la seule valide.",
    "icon": "target"
  },
  {
    "id": 42,
    "name": "Curse of Knowledge",
    "nameFr": "Malédiction de la connaissance",
    "slug": "curse-of-knowledge",
    "summary": "Difficulty imagining what it\\'s like not to know something",
    "summaryFr": "Difficulté à imaginer ce que c\\'est de ne pas savoir quelque chose",
    "description": "The curse of knowledge, popularized by Chip and Dan Heath in \"Made to Stick,\" is the cognitive difficulty of imagining what it\\'s like not to know something you know. Once we possess knowledge, we find it nearly impossible to recreate the state of not having it. Elizabeth Newton\\'s famous \"tappers and listeners\" experiment demonstrated this: tappers who tapped the rhythm of a well-known song predicted listeners would recognize it 50% of the time, but listeners succeeded only 2.5% of the time. Tappers couldn\\'t imagine not hearing the melody they heard in their heads. The curse plagues experts trying to communicate with novices—using jargon, skipping \"obvious\" steps, or assuming background knowledge. Teachers, writers, and product designers all struggle with it. It causes documentation that only makes sense to those who already understand, training that moves too fast, and products designed for experts rather than intended users. Overcoming the curse requires actively testing understanding with actual novices, using concrete examples rather than abstractions, building in feedback loops, and practicing what Steven Pinker calls \"reader-friendly writing\"—consciously modeling the reader\\'s knowledge state.",
    "descriptionFr": "La malédiction de la connaissance, popularisée par Chip et Dan Heath dans \"Made to Stick,\" est la difficulté cognitive d\\'imaginer ce que c\\'est de ne pas savoir quelque chose qu\\'on sait. Une fois que nous possédons une connaissance, nous trouvons presque impossible de recréer l\\'état de ne pas l\\'avoir. La célèbre expérience \"tappers and listeners\" d\\'Elizabeth Newton l\\'a démontré : les tapeurs qui tapaient le rythme d\\'une chanson connue prédisaient que les auditeurs la reconnaîtraient 50% du temps, mais les auditeurs ne réussissaient que 2,5% du temps. Les tapeurs ne pouvaient pas imaginer ne pas entendre la mélodie qu\\'ils entendaient dans leur tête. La malédiction touche les experts essayant de communiquer avec les novices—utilisant du jargon, sautant des étapes \"évidentes,\" ou supposant des connaissances de base. Enseignants, écrivains et concepteurs de produits en souffrent tous. Elle cause une documentation qui n\\'a de sens que pour ceux qui comprennent déjà, des formations qui vont trop vite, et des produits conçus pour les experts plutôt que les utilisateurs visés. Surmonter la malédiction nécessite de tester activement la compréhension avec de vrais novices, utiliser des exemples concrets plutôt que des abstractions, et pratiquer l\\'écriture orientée lecteur.",
    "example": "A developer explaining a feature in technical jargon. A teacher assuming students understand the basics. Documentation that only makes sense to those who already understand.",
    "exampleFr": "Un développeur expliquant une fonctionnalité en jargon technique. Un enseignant supposant que les étudiants comprennent les bases. Une documentation qui n\\'a de sens que pour ceux qui comprennent déjà.",
    "icon": "eye"
  },
  {
    "id": 43,
    "name": "Mere Exposure Effect",
    "nameFr": "Effet de simple exposition",
    "slug": "mere-exposure-effect",
    "summary": "Preferring things simply because they\\'re familiar",
    "summaryFr": "Préférer les choses simplement parce qu\\'elles sont familières",
    "description": "The mere exposure effect, extensively researched by Robert Zajonc, is the phenomenon whereby repeated exposure to a stimulus increases liking for it, independent of any conscious evaluation. Simply encountering something more frequently makes us feel more positively toward it. This occurs subconsciously and applies to words, faces, songs, brands, and even abstract shapes. The effect evolved because familiarity often correlates with safety—what we\\'ve encountered before and survived is probably not dangerous. But in modern contexts, it creates biases. We prefer incumbent vendors, familiar products, and people we\\'ve seen before—not because they\\'re objectively better, but because familiarity feels good. Advertising exploits this: brand awareness alone, even without persuasive content, increases preference. In hiring, candidates who seem familiar (similar backgrounds, shared contacts) feel more trustworthy. In decision-making, familiar options feel less risky. The effect has limits—overexposure can lead to boredom or irritation, and initially negative stimuli may become more negative. Counteracting it requires awareness that familiarity creates warmth, deliberately exposing yourself to unfamiliar alternatives, and evaluating options on explicit criteria rather than gut feelings that may merely reflect exposure.",
    "descriptionFr": "L\\'effet de simple exposition, étudié extensivement par Robert Zajonc, est le phénomène par lequel l\\'exposition répétée à un stimulus augmente l\\'attrait pour celui-ci, indépendamment de toute évaluation consciente. Simplement rencontrer quelque chose plus fréquemment nous fait nous sentir plus positivement envers elle. Cela se produit inconsciemment et s\\'applique aux mots, visages, chansons, marques, et même aux formes abstraites. L\\'effet a évolué parce que la familiarité est souvent corrélée à la sécurité—ce que nous avons rencontré avant et survécu n\\'est probablement pas dangereux. Mais dans les contextes modernes, il crée des biais. Nous préférons les fournisseurs en place, les produits familiers, et les personnes que nous avons vues avant—pas parce qu\\'ils sont objectivement meilleurs, mais parce que la familiarité fait du bien. La publicité exploite cela : la notoriété de marque seule, même sans contenu persuasif, augmente la préférence. En recrutement, les candidats qui semblent familiers (parcours similaires, contacts partagés) semblent plus dignes de confiance. Contrer cela nécessite une conscience que la familiarité crée de la chaleur, s\\'exposer délibérément aux alternatives non familières, et évaluer les options sur des critères explicites plutôt que des sentiments instinctifs qui peuvent simplement refléter l\\'exposition.",
    "example": "Preferring a vendor you\\'ve used before even when a new one offers better terms. Choosing the brand you recognize. Liking colleagues you see frequently more than those you rarely encounter.",
    "exampleFr": "Préférer un fournisseur utilisé avant même si un nouveau offre de meilleures conditions. Choisir la marque que vous reconnaissez. Aimer davantage les collègues que vous voyez fréquemment que ceux que vous rencontrez rarement.",
    "icon": "scale"
  },
  {
    "id": 44,
    "name": "Reactance",
    "nameFr": "Réactance",
    "slug": "reactance",
    "summary": "Doing the opposite when told what to do",
    "summaryFr": "Faire le contraire quand on vous dit quoi faire",
    "description": "Reactance, theorized by Jack Brehm, is the psychological pushback we experience when we perceive our freedom as threatened. When told we can\\'t or must do something, we often want to do exactly the opposite—not because it\\'s better, but to reassert our autonomy. This creates paradoxical effects: banning something can make it more desirable (the \"forbidden fruit\" effect), heavy-handed persuasion can backfire, and mandating behavior can create resistance even to beneficial actions. Adolescent rebellion is partly reactance in action. In organizations, top-down mandates without buy-in often face resistance that wouldn\\'t exist if the same changes were suggested or co-created. In marketing, aggressive sales techniques can push customers away. In relationships, telling someone they \"have to\" do something often ensures they won\\'t. Reactance is stronger in people who highly value autonomy and in cultures that emphasize individual freedom. Managing reactance requires understanding that how you present choices matters as much as the choices themselves. Offering options rather than mandates, explaining the \"why\" behind requirements, involving people in decisions that affect them, and using \"restore freedom\" language (\"you have every right to decide\") can reduce resistance.",
    "descriptionFr": "La réactance, théorisée par Jack Brehm, est le rejet psychologique que nous expérimentons quand nous percevons notre liberté comme menacée. Quand on nous dit qu\\'on ne peut pas ou qu\\'on doit faire quelque chose, nous voulons souvent faire exactement le contraire—pas parce que c\\'est mieux, mais pour réaffirmer notre autonomie. Cela crée des effets paradoxaux : interdire quelque chose peut le rendre plus désirable (l\\'effet \"fruit défendu\"), la persuasion lourde peut se retourner contre elle-même, et imposer un comportement peut créer de la résistance même à des actions bénéfiques. La rébellion adolescente est en partie la réactance en action. Dans les organisations, les mandats descendants sans adhésion font souvent face à une résistance qui n\\'existerait pas si les mêmes changements étaient suggérés ou co-créés. En marketing, les techniques de vente agressives peuvent repousser les clients. Gérer la réactance nécessite de comprendre que la façon de présenter les choix compte autant que les choix eux-mêmes. Offrir des options plutôt que des mandats, expliquer le \"pourquoi\" derrière les exigences, impliquer les gens dans les décisions qui les affectent, et utiliser un langage de \"restauration de liberté\" peuvent réduire la résistance.",
    "example": "Rejecting a good policy just because it was mandated. Wanting something more because it\\'s forbidden. Resisting beneficial changes imposed without consultation.",
    "exampleFr": "Rejeter une bonne politique juste parce qu\\'elle a été imposée. Vouloir quelque chose davantage parce que c\\'est interdit. Résister à des changements bénéfiques imposés sans consultation.",
    "icon": "clock"
  },
  {
    "id": 45,
    "name": "Present Bias",
    "nameFr": "Biais du présent",
    "slug": "present-bias",
    "summary": "Overvaluing immediate rewards over future benefits",
    "summaryFr": "Surévaluer les récompenses immédiates par rapport aux bénéfices futurs",
    "description": "Present bias (closely related to hyperbolic discounting) is the tendency to weight present payoffs more heavily than future ones when making intertemporal choices. While related to hyperbolic discounting, present bias focuses specifically on the extra weight given to \"now\" versus \"later,\" regardless of how much later. This creates systematic under-investment in the future: we procrastinate on tasks with delayed benefits, undersave for retirement, skip exercise for immediate comfort, and choose immediate pleasures over long-term goals. Present bias explains why people often fail to follow through on plans their past selves made: the \"planner\" self that committed to healthy eating or regular exercise loses out to the \"doer\" self that wants immediate gratification. Behavioral economists have developed interventions leveraging commitment devices (making it costly to deviate from planned behavior), automatic enrollment (making future-oriented choices the default), and making future rewards more vivid and concrete. Understanding present bias is crucial for designing systems that help people achieve their long-term goals despite their present-focused impulses—from retirement savings programs to health interventions to environmental policies.",
    "descriptionFr": "Le biais du présent (étroitement lié à la dévaluation hyperbolique) est la tendance à pondérer les gains présents plus lourdement que les futurs lors des choix intertemporels. Bien que lié à la dévaluation hyperbolique, le biais du présent se concentre spécifiquement sur le poids supplémentaire donné à \"maintenant\" versus \"plus tard.\" Cela crée un sous-investissement systématique dans le futur : nous procrastinons sur les tâches aux bénéfices différés, sous-épargnons pour la retraite, sautons l\\'exercice pour le confort immédiat, et choisissons les plaisirs immédiats plutôt que les objectifs à long terme. Le biais du présent explique pourquoi les gens échouent souvent à suivre les plans que leur moi passé a faits : le moi \"planificateur\" qui s\\'est engagé à manger sainement ou à faire de l\\'exercice régulièrement perd face au moi \"exécuteur\" qui veut une gratification immédiate. Les économistes comportementaux ont développé des interventions utilisant des dispositifs d\\'engagement (rendre coûteux de dévier du comportement planifié), l\\'inscription automatique (faire des choix orientés vers le futur le défaut), et rendre les récompenses futures plus vivides et concrètes. Comprendre le biais du présent est crucial pour concevoir des systèmes qui aident les gens à atteindre leurs objectifs à long terme malgré leurs impulsions centrées sur le présent.",
    "example": "Spending on a vacation instead of investing for retirement. Skipping exercise for immediate comfort. Choosing short-term profits over long-term sustainability.",
    "exampleFr": "Dépenser pour des vacances au lieu d\\'investir pour la retraite. Sauter l\\'exercice pour le confort immédiat. Choisir les profits à court terme plutôt que la durabilité à long terme.",
    "icon": "zap"
  },
  {
    "id": 46,
    "name": "Omission Bias",
    "nameFr": "Biais d\\'omission",
    "slug": "omission-bias",
    "summary": "Preferring inaction even when action would cause less harm",
    "summaryFr": "Préférer l\\'inaction même quand l\\'action causerait moins de tort",
    "description": "Omission bias is the tendency to judge harmful actions as morally worse than equally harmful omissions (failures to act). We feel less responsible for bad outcomes caused by inaction than by action, even when the consequences are identical. Classic thought experiments illustrate this: most people find it more acceptable to let someone die by not intervening than to actively cause their death, even when the outcome is the same. This bias has significant implications. In medicine, doctors may be more reluctant to recommend treatments that have known risks than to recommend inaction that produces the same statistical risk of harm. In organizations, managers may tolerate deteriorating situations (omission) while being unwilling to take actions that might cause comparable disruption. The bias likely evolved because actions are more traceable to individuals than omissions, creating greater social accountability. But it leads to suboptimal decisions when inaction is actually more harmful. Overcoming omission bias requires explicitly comparing the consequences of action versus inaction, recognizing that \"doing nothing\" is itself a choice with consequences, and accepting appropriate responsibility for outcomes we could have prevented.",
    "descriptionFr": "Le biais d\\'omission est la tendance à juger les actions nuisibles comme moralement pires que les omissions tout aussi nuisibles (défauts d\\'agir). Nous nous sentons moins responsables des mauvais résultats causés par l\\'inaction que par l\\'action, même quand les conséquences sont identiques. Des expériences de pensée classiques illustrent cela : la plupart des gens trouvent plus acceptable de laisser quelqu\\'un mourir en n\\'intervenant pas que de causer activement sa mort, même quand le résultat est le même. Ce biais a des implications significatives. En médecine, les médecins peuvent être plus réticents à recommander des traitements ayant des risques connus qu\\'à recommander l\\'inaction qui produit le même risque statistique de préjudice. Dans les organisations, les managers peuvent tolérer des situations qui se détériorent (omission) tout en étant réticents à prendre des actions qui pourraient causer une perturbation comparable. Le biais a probablement évolué parce que les actions sont plus traçables aux individus que les omissions, créant une plus grande responsabilité sociale. Mais il mène à des décisions sous-optimales quand l\\'inaction est en réalité plus nuisible. Surmonter le biais d\\'omission nécessite de comparer explicitement les conséquences de l\\'action versus l\\'inaction et de reconnaître que \"ne rien faire\" est lui-même un choix avec des conséquences.",
    "example": "Not intervening in a toxic team dynamic because you didn\\'t \"cause\" it. Avoiding a difficult conversation that would prevent greater harm. Letting problems fester rather than addressing them.",
    "exampleFr": "Ne pas intervenir dans une dynamique d\\'équipe toxique parce que vous ne l\\'avez pas \"causée.\" Éviter une conversation difficile qui préviendrait un plus grand tort. Laisser les problèmes s\\'envenimer plutôt que les traiter.",
    "icon": "shield"
  },
  {
    "id": 47,
    "name": "Clustering Illusion",
    "nameFr": "Illusion de regroupement",
    "slug": "clustering-illusion",
    "summary": "Seeing patterns in random data",
    "summaryFr": "Voir des motifs dans des données aléatoires",
    "description": "The clustering illusion is the tendency to perceive meaningful patterns in what is actually random data. Our brains are pattern-recognition machines—excellent for survival but prone to false positives. We expect random sequences to look \"random\" (evenly distributed), but true randomness often includes clusters and streaks that appear non-random. Flip a coin 100 times and you\\'ll likely see runs of 5-6 heads or tails—not evidence of a pattern, just probability. Amos Tversky and Thomas Gilovich debunked the \"hot hand\" in basketball, showing that perceived streaks were within the range of random variation. Yet the belief persisted because clusters feel meaningful. The illusion affects investing (seeing patterns in stock movements), management (detecting \"trends\" in small samples), and science (finding false positives in noisy data). It\\'s amplified by confirmation bias—once we think we see a pattern, we notice confirming instances and ignore exceptions. Correcting the illusion requires statistical literacy, understanding what true randomness looks like, demanding adequate sample sizes before drawing conclusions, and applying formal statistical tests rather than relying on visual pattern recognition.",
    "descriptionFr": "L\\'illusion de regroupement est la tendance à percevoir des motifs significatifs dans ce qui est en réalité des données aléatoires. Nos cerveaux sont des machines de reconnaissance de motifs—excellentes pour la survie mais sujettes aux faux positifs. Nous nous attendons à ce que les séquences aléatoires semblent \"aléatoires\" (distribuées uniformément), mais le véritable hasard inclut souvent des regroupements et des séries qui semblent non aléatoires. Lancez une pièce 100 fois et vous verrez probablement des séries de 5-6 faces ou piles—pas une preuve de motif, juste la probabilité. Amos Tversky et Thomas Gilovich ont démystifié la \"main chaude\" au basketball, montrant que les séries perçues étaient dans la plage de variation aléatoire. Pourtant la croyance a persisté parce que les regroupements semblent significatifs. L\\'illusion affecte l\\'investissement (voir des motifs dans les mouvements boursiers), le management (détecter des \"tendances\" dans de petits échantillons), et la science (trouver des faux positifs dans des données bruitées). Elle est amplifiée par le biais de confirmation—une fois que nous pensons voir un motif, nous remarquons les instances confirmantes et ignorons les exceptions. Corriger l\\'illusion nécessite une littératie statistique et de demander des tailles d\\'échantillon adéquates avant de tirer des conclusions.",
    "example": "Believing a salesperson is on a \"hot streak\" when their wins are random. Seeing patterns in stock price movements that are just noise. Detecting \"trends\" in small data samples.",
    "exampleFr": "Croire qu\\'un vendeur est sur une \"série gagnante\" quand ses succès sont aléatoires. Voir des motifs dans les mouvements de prix qui ne sont que du bruit. Détecter des \"tendances\" dans de petits échantillons de données.",
    "icon": "users"
  },
  {
    "id": 48,
    "name": "Moral Licensing",
    "nameFr": "Licence morale",
    "slug": "moral-licensing",
    "summary": "Feeling entitled to bad behavior after doing good",
    "summaryFr": "Se sentir autorisé à mal agir après avoir fait le bien",
    "description": "Moral licensing is the psychological phenomenon where past good behavior creates a sense of \"moral credits\" that permits subsequent questionable behavior. Having done something virtuous, we feel licensed to be less virtuous next time—as if morality were a bank account that can be deposited into and withdrawn from. Research shows that people who refused to make prejudiced statements were more likely to discriminate later; people who expressed egalitarian beliefs felt freer to make stereotyped judgments; those who recalled past charitable acts donated less to charity. The effect extends beyond ethics: after exercising, people often eat more; after buying \"green\" products, people behave less environmentally. Licensing also works prospectively: intending to be good later can license being bad now. In organizations, moral licensing explains why diversity initiatives sometimes backfire, why companies with strong CSR programs still have ethical lapses, and why individuals who see themselves as ethical may be blind to their own transgressions. Counteracting moral licensing requires treating ethical behavior as reflecting identity rather than earning credits, maintaining consistent standards rather than compensating across domains, and being especially vigilant after feeling virtuous.",
    "descriptionFr": "La licence morale est le phénomène psychologique où un bon comportement passé crée un sentiment de \"crédits moraux\" qui permet un comportement ultérieur discutable. Ayant fait quelque chose de vertueux, nous nous sentons autorisés à être moins vertueux la prochaine fois—comme si la moralité était un compte bancaire dans lequel on peut déposer et retirer. La recherche montre que les personnes ayant refusé de faire des déclarations préjudiciables étaient plus susceptibles de discriminer plus tard ; les personnes ayant exprimé des croyances égalitaires se sentaient plus libres de porter des jugements stéréotypés ; ceux ayant rappelé des actes charitables passés donnaient moins à la charité. L\\'effet s\\'étend au-delà de l\\'éthique : après l\\'exercice, les gens mangent souvent plus ; après avoir acheté des produits \"verts,\" les gens se comportent de manière moins environnementale. Dans les organisations, la licence morale explique pourquoi les initiatives de diversité échouent parfois, pourquoi les entreprises avec de forts programmes RSE ont encore des manquements éthiques, et pourquoi les individus qui se voient comme éthiques peuvent être aveugles à leurs propres transgressions. Contrer la licence morale nécessite de traiter le comportement éthique comme reflétant l\\'identité plutôt que de gagner des crédits et de maintenir des standards cohérents.",
    "example": "After completing diversity training, feeling okay to make an insensitive joke. Eating more after exercising. Feeling entitled to cut corners after working overtime.",
    "exampleFr": "Après avoir terminé une formation sur la diversité, sentir que c\\'est acceptable de faire une blague insensible. Manger plus après avoir fait de l\\'exercice. Se sentir autorisé à couper les coins après avoir fait des heures supplémentaires.",
    "icon": "trending-up"
  },
  {
    "id": 49,
    "name": "Peak-end Rule",
    "nameFr": "Règle du pic et de la fin",
    "slug": "peak-end-rule",
    "summary": "Judging experiences by their peaks and endings, not totals",
    "summaryFr": "Juger les expériences par leurs pics et fins, pas les totaux",
    "description": "The peak-end rule, discovered by Daniel Kahneman, describes how we remember and evaluate experiences based not on their total or average, but on their most intense moment (the peak) and how they ended. Duration matters surprisingly little—a phenomenon Kahneman called \"duration neglect.\" In studies of colonoscopy patients, those whose procedures ended with a less painful (though longer) period rated the entire experience more favorably than those with shorter but abruptly ending procedures. This has profound implications for experience design. A vacation with one spectacular day and a pleasant last day will be remembered more fondly than a uniformly good vacation. Customer experiences, medical procedures, negotiations, and even relationships are evaluated by peaks and endings. The rule explains why endings matter so much in movies, why \"saving the best for last\" is effective, and why a single terrible experience can outweigh many good ones. Designing for the peak-end rule means creating memorable high points, ensuring positive endings, and recognizing that duration is less important than how an experience feels at its most intense and final moments.",
    "descriptionFr": "La règle du pic et de la fin, découverte par Daniel Kahneman, décrit comment nous nous souvenons et évaluons les expériences basées non sur leur total ou moyenne, mais sur leur moment le plus intense (le pic) et comment elles se sont terminées. La durée compte étonnamment peu—un phénomène que Kahneman appelait \"négligence de la durée.\" Dans des études sur les patients de coloscopie, ceux dont les procédures se terminaient par une période moins douloureuse (bien que plus longue) évaluaient l\\'expérience entière plus favorablement que ceux avec des procédures plus courtes mais se terminant abruptement. Cela a des implications profondes pour la conception d\\'expériences. Des vacances avec une journée spectaculaire et un dernier jour agréable seront mémorisées plus chaleureusement que des vacances uniformément bonnes. Les expériences clients, procédures médicales, négociations, et même les relations sont évaluées par les pics et les fins. La règle explique pourquoi les fins comptent tant dans les films, pourquoi \"garder le meilleur pour la fin\" est efficace, et pourquoi une seule expérience terrible peut l\\'emporter sur de nombreuses bonnes. Concevoir pour la règle pic-fin signifie créer des points forts mémorables et assurer des fins positives.",
    "example": "Rating a project as successful because it ended well, despite months of problems. Remembering a vacation by its best day and last day. A great dessert redeeming an average meal.",
    "exampleFr": "Évaluer un projet comme réussi parce qu\\'il s\\'est bien terminé, malgré des mois de problèmes. Se souvenir de vacances par leur meilleur jour et dernier jour. Un excellent dessert rachetant un repas moyen.",
    "icon": "lightbulb"
  },
  {
    "id": 50,
    "name": "Effort Justification",
    "nameFr": "Justification de l\\'effort",
    "slug": "effort-justification",
    "summary": "Valuing things more because they required effort",
    "summaryFr": "Valoriser davantage les choses parce qu\\'elles ont demandé des efforts",
    "description": "Effort justification, a form of cognitive dissonance reduction studied by Leon Festinger and Elliot Aronson, is the tendency to value outcomes more when they required significant effort, regardless of the outcome\\'s objective quality. If we worked hard for something, it must be valuable—otherwise, why did we work so hard? This creates a self-reinforcing cycle where effort creates perceived value. Classic research showed that people who underwent severe initiations valued group membership more than those with easy entry—not because the groups were better, but because the effort needed justification. In organizations, effort justification makes us defend inefficient processes we struggled to implement, overvalue solutions we worked hard to create, and resist abandoning projects we\\'ve invested significant effort in (related to sunk cost fallacy). It explains the appeal of hazing rituals, difficult interview processes, and expensive luxury goods. The bias is adaptive in some ways—it helps us persist through genuine difficulties—but becomes problematic when effort becomes a proxy for value. Counteracting it requires evaluating outcomes independently of the effort invested, asking whether the effort was actually necessary or just incurred, and being willing to abandon hard-won positions when better alternatives emerge.",
    "descriptionFr": "La justification de l\\'effort, une forme de réduction de la dissonance cognitive étudiée par Leon Festinger et Elliot Aronson, est la tendance à valoriser davantage les résultats quand ils ont nécessité un effort significatif, indépendamment de la qualité objective du résultat. Si nous avons travaillé dur pour quelque chose, cela doit être précieux—sinon, pourquoi avons-nous travaillé si dur ? Cela crée un cycle auto-renforçant où l\\'effort crée une valeur perçue. La recherche classique a montré que les personnes ayant subi des initiations sévères valorisaient davantage l\\'appartenance au groupe que celles avec une entrée facile—pas parce que les groupes étaient meilleurs, mais parce que l\\'effort nécessitait une justification. Dans les organisations, la justification de l\\'effort nous fait défendre des processus inefficaces que nous avons eu du mal à mettre en place, surévaluer les solutions pour lesquelles nous avons travaillé dur, et résister à abandonner des projets dans lesquels nous avons investi des efforts significatifs (lié à l\\'erreur des coûts irrécupérables). Le biais explique l\\'attrait des rituels de bizutage, des processus d\\'entretien difficiles, et des biens de luxe coûteux. Contrer cela nécessite d\\'évaluer les résultats indépendamment de l\\'effort investi et d\\'être prêt à abandonner des positions durement acquises quand de meilleures alternatives émergent.",
    "example": "Defending a complicated process because \"we worked hard to set it up.\" Valuing a difficult degree more than an easier one with the same outcomes. Overvaluing hard-won solutions.",
    "exampleFr": "Défendre un processus compliqué parce que \"nous avons travaillé dur pour le mettre en place.\" Valoriser un diplôme difficile plus qu\\'un plus facile avec les mêmes résultats. Surévaluer les solutions durement acquises.",
    "icon": "compass"
  }
]
